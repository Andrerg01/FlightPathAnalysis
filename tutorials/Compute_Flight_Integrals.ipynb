{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Fuel, Time, Spatial, and weather integrals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# This variable should indicate the path from this Jupyter Notebook to the root directory of the repo.\n",
    "root_path = '../'\n",
    "# Adds the repo's root to the list of paths\n",
    "sys.path.append(root_path)\n",
    "\n",
    "# Package to read yml files\n",
    "import yaml\n",
    "# Package to handle file paths\n",
    "import os\n",
    "# Package to deal with DataFrames\n",
    "import pandas as pd\n",
    "# Package to plot stuff\n",
    "import matplotlib.pyplot as plt\n",
    "# Package for numerical and array handling\n",
    "import numpy as np\n",
    "# Package to read and write to .sqlite files\n",
    "import sqlite3\n",
    "# Package to keep track of time\n",
    "import datetime\n",
    "\n",
    "# Function to clear output from jupyter notebook\n",
    "from IPython.display import clear_output\n",
    "# Package for compressing dataframes into file\n",
    "from src.data import compressors\n",
    "# Package for defining and fitting weather models\n",
    "from src.models import weather\n",
    "# Utilities package\n",
    "from src.common import utils\n",
    "# Package for interpolating and estimating weather\n",
    "from src.analysis import weather_interpolator\n",
    "\n",
    "def sigmoid(x, mu = 0, sig = 1):\n",
    "    return 1/(1+np.exp(-(x - mu)/sig))\n",
    "\n",
    "# Time Integral\n",
    "def integrate_time(state_vectors):\n",
    "    return state_vectors['time'].iloc[-1] - state_vectors['time'].iloc[0]\n",
    "\n",
    "def integrate_fuel(state_vectors):\n",
    "    return state_vectors['used_fuel'].iloc[-1]\n",
    "\n",
    "# Wind Integral\n",
    "def integrate_wind(state_vectors):\n",
    "    speed_of_sound = 666.739\n",
    "    return np.sum(state_vectors['sknt'])/(speed_of_sound*len(state_vectors))\n",
    "\n",
    "# Air Density Integral\n",
    "def integrate_air_density(state_vectors):\n",
    "    sea_level_density = 1.204\n",
    "    return np.sum(state_vectors['air_density'])/(sea_level_density*len(state_vectors))\n",
    "\n",
    "def integrate_air_pressure(state_vectors):\n",
    "    sea_level_pressure = 1013.25\n",
    "    return np.sum(state_vectors['air_pressure'])/(sea_level_pressure*len(state_vectors))\n",
    "\n",
    "def integrate_clouds(state_vectors):\n",
    "    max_clouds = 1\n",
    "    return np.sum(state_vectors['clouds'])/(max_clouds*len(state_vectors))\n",
    "\n",
    "def integrate_severity(state_vectors):\n",
    "    max_severity = 1\n",
    "    return np.sum(state_vectors['severity'])/(max_severity*len(state_vectors))\n",
    "\n",
    "\n",
    "def integrate_distance(state_vectors):\n",
    "    d = 0\n",
    "    for row_a, row_b in zip(state_vectors[:-1].itertuples(), state_vectors[1:].itertuples()):\n",
    "        d += utils.haversine_distance(row_a.lat, row_a.lon, row_b.lat, row_b.lon)\n",
    "    return d\n",
    "\n",
    "# Path from this notebook to the root directory\n",
    "root_path = os.path.normpath(root_path)\n",
    "# Path from root to the desired config file\n",
    "config_path_from_root = os.path.normpath('config/config.yml')\n",
    "# Defining path from this notebook to config file\n",
    "config_path = os.path.join(root_path, config_path_from_root)\n",
    "\n",
    "# Loading config file\n",
    "with open(config_path, 'r',  encoding='utf8') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Defining \"clear-output\" function to feed into logger\n",
    "def clear():\n",
    "    clear_output(wait=True)\n",
    "\n",
    "# Creates an instance of a logger class to log all that happens, optional (but encouraged).\n",
    "logger = utils.Logger(config, clear_function=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = ['../data/flight/' + f for f in os.listdir('../data/flight/') if f.endswith('.sqlite')]\n",
    "\n",
    "for file in files:\n",
    "    flights_database = file\n",
    "\n",
    "    conn = sqlite3.connect(flights_database)\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    table_name = 'state_vector_weather'\n",
    "    \n",
    "    query = f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}';\"\n",
    "    \n",
    "    # Execute the query\n",
    "    cursor.execute(query)\n",
    "    \n",
    "    result = cursor.fetchone()\n",
    "    \n",
    "    if result:\n",
    "        \n",
    "        cursor.execute(\"DROP TABLE IF EXISTS flights_integrals;\")\n",
    "\n",
    "        new_columns = ['time', 'fuel', 'distance', 'wind', 'air_density', 'air_pressure', 'clouds', 'severity']\n",
    "\n",
    "        # Create the new table\n",
    "        create_table_query = f'''\n",
    "            CREATE TABLE flights_integrals (\n",
    "                flight_id TEXT PRIMARY KEY,\n",
    "                {\", \".join([f\"{col} REAL\" for col in new_columns])}\n",
    "            );\n",
    "        '''\n",
    "        # Create the new table if it doesn't exist\n",
    "        cursor.execute(create_table_query) \n",
    "\n",
    "        flight_ids, icao24s = pd.read_sql_query(\"SELECT flight_id, icao24 FROM flights\", conn).values.T\n",
    "\n",
    "        i = 0\n",
    "        for flight_id, icao24 in zip(flight_ids, icao24s):\n",
    "            clear_output(wait=True)\n",
    "            print(f'{i}/{len(flight_ids)} | {flight_id}')\n",
    "            state_vectors = pd.read_sql_query(f\"\"\"\n",
    "                SELECT DISTINCT sv.*, svw.*, svf.*\n",
    "                FROM state_vectors sv\n",
    "                JOIN flights ON flights.flight_id = sv.flight_id\n",
    "                LEFT JOIN state_vector_weather svw ON svw.vector_id = sv.vector_id\n",
    "                LEFT JOIN state_vector_fuel svf ON svf.vector_id = sv.vector_id\n",
    "                WHERE sv.flight_id = '{flight_id}';\n",
    "                                               \"\"\",\n",
    "                                               conn)\n",
    "            state_vectors = state_vectors.iloc[:, ::-1]\n",
    "\n",
    "            # Drop duplicated column names, keeping the first occurrence (which is actually the last in the original DataFrame)\n",
    "            state_vectors = state_vectors.loc[:, ~state_vectors.columns.duplicated(keep='first')]\n",
    "\n",
    "            # Reverse the column order back to original\n",
    "            state_vectors = state_vectors.iloc[:, ::-1]\n",
    "\n",
    "            integrals = {'flight_id': flight_id,\n",
    "                        'time': integrate_time(state_vectors),\n",
    "                        'fuel': integrate_fuel(state_vectors),\n",
    "                        'distance': integrate_distance(state_vectors),\n",
    "                        'wind': integrate_wind(state_vectors),\n",
    "                        'air_density': integrate_air_density(state_vectors),\n",
    "                        'air_pressure': integrate_air_pressure(state_vectors),\n",
    "                        'clouds': integrate_clouds(state_vectors),\n",
    "                        'severity': integrate_severity(state_vectors)}\n",
    "\n",
    "            insert_data = tuple(integrals.values())\n",
    "            # Creating query to insert new values\n",
    "            insert_query = f'''\n",
    "                INSERT INTO flights_integrals (flight_id, {', '.join(new_columns)})\n",
    "                VALUES ({', '.join('?' * len(insert_data))})\n",
    "                ON CONFLICT(flight_id) DO UPDATE SET\n",
    "                {', '.join([f\"{col} = excluded.{col}\" for col in new_columns])};\n",
    "            '''\n",
    "            cursor.execute(insert_query, insert_data)\n",
    "\n",
    "            conn.commit()\n",
    "\n",
    "            i += 1\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flight_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "files = ['../data/flight/' + f for f in os.listdir('../data/flight/') if f.endswith('.sqlite')]\n",
    "\n",
    "for file in files:\n",
    "    print('=========')\n",
    "    print(file)\n",
    "    conn = sqlite3.connect(file)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cur.fetchall()\n",
    "    tables = [table[0] for table in tables]\n",
    "    counts = {table:0 for table in tables}\n",
    "    for table in tables:\n",
    "        cur.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
    "        row_count = cur.fetchone()[0]\n",
    "        print(f\"{table}: {row_count}\")\n",
    "        counts[table] = row_count        \n",
    "    \n",
    "    strout = file\n",
    "    if \"state_vector_weather\" in tables:\n",
    "        strout += ' | Weather: Yes'\n",
    "    else:\n",
    "        strout += ' | Weather: No'\n",
    "    if \"state_vector_fuel\" in tables:\n",
    "        strout += ' | Fuel: Yes'\n",
    "    else:\n",
    "        strout += ' | Fuel: No'\n",
    "    print(strout)\n",
    "    \n",
    "    conn.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../data/flight/KSFO_KLAX_2023-01-01_2023-01-31.sqlite\"\n",
    "conn = sqlite3.connect(file)\n",
    "\n",
    "fuels = pd.read_sql_query(f\"\"\"\n",
    "    SELECT fi.*, fs.icao24\n",
    "    FROM flights_integrals AS fi\n",
    "    JOIN flights as fs ON fs.flight_id = fi.flight_id\n",
    "    ;\"\"\",conn)\n",
    "fuels = fuels.dropna().sort_values('fuel')\n",
    "flight_id = fuels.iloc[0]['flight_id']\n",
    "\n",
    "state_vectors = pd.read_sql_query(f\"\"\"\n",
    "    SELECT DISTINCT sv.*, svw.*, svf.*, fi.*\n",
    "    FROM state_vectors sv\n",
    "    JOIN state_vector_weather svw ON svw.vector_id = sv.vector_id\n",
    "    LEFT JOIN state_vector_fuel svf ON svf.vector_id = sv.vector_id\n",
    "    LEFT JOIN flights as fi ON sv.flight_id = fi.flight_id\n",
    "    WHERE sv.flight_id = '{flight_id}';\"\"\"\n",
    "                                  ,conn)\n",
    "conn.close()\n",
    "\n",
    "fuels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traffic.core import Flight\n",
    "typecodes = []\n",
    "for icao24 in fuels['icao24']:\n",
    "    df = pd.DataFrame({'icao24':[icao24], 'timestamp':[0]})\n",
    "    typecodes += [Flight(df).aircraft['typecode']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuels['typecode'] = typecodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flight(df).aircraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots( figsize = [10, 10/1.62])\n",
    "aircrafts, counts = np.unique(typecodes, return_counts=True)\n",
    "thresh = 20\n",
    "mask = counts >= thresh\n",
    "aircrafts = aircrafts[mask]\n",
    "counts = counts[mask]\n",
    "for i, aicraft_type in enumerate(aircrafts):\n",
    "    ax.hist(fuels[fuels['typecode'] == aicraft_type]['fuel'], bins = 10, histtype = 'step', label = aicraft_type)\n",
    "ax.legend()\n",
    "ax.set_title(f\"Fuel Consumption of different aircraft types ({thresh} flights or more)\")\n",
    "ax.set_xlabel('Fuel Consumption (kg)')\n",
    "ax.set_ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get optimal flight path\n",
    "# We need the weather calculation for the optimal path for the time of each of the other flights -> state_vector_weather_optimal\n",
    "# Integrals for optimal -> flights_integrals_optimal\n",
    "# flight time Vs weather\n",
    "# distance Vs flight_time\n",
    "# Plane Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "file = \"../data/flight/KSFO_KLAX_2023-01-01_2023-01-31.sqlite\"\n",
    "conn = sqlite3.connect(file)\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT DISTINCT sv.vector_id, sv.time_normalized, sv.lat, sv.lon, svf.mass, svf.fuelflow\n",
    "    FROM state_vectors AS sv\n",
    "    JOIN state_vector_fuel svf ON svf.vector_id = sv.vector_id\n",
    "    LEFT JOIN flights as fs ON sv.flight_id = fs.flight_id\n",
    "    WHERE sv.flight_id = \"a4c0db_1672545968_1672549575_KSFO_KLAX\";\"\"\"\n",
    "df = pd.read_sql_query(query,conn)\n",
    "\n",
    "conn.close()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FlightStats",
   "language": "python",
   "name": "flightstats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
