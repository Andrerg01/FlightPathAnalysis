{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Weather for Each Flight Optimal Route with Parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# This variable should indicate the path from this Jupyter Notebook to the root directory of the repo.\n",
    "root_path = '../'\n",
    "# Adds the repo's root to the list of paths\n",
    "sys.path.append(root_path)\n",
    "\n",
    "# Package to read yml files\n",
    "import yaml\n",
    "# Package to handle file paths\n",
    "import os\n",
    "# Package to deal with DataFrames\n",
    "import pandas as pd\n",
    "# Package to plot stuff\n",
    "import matplotlib.pyplot as plt\n",
    "# Package for numerical and array handling\n",
    "import numpy as np\n",
    "# Package to read and write to .sqlite files\n",
    "import sqlite3\n",
    "# Package to keep track of time\n",
    "import datetime\n",
    "\n",
    "# Function to clear output from jupyter notebook\n",
    "from IPython.display import clear_output\n",
    "# Package for compressing dataframes into file\n",
    "from src.data import compressors\n",
    "# Package for defining and fitting weather models\n",
    "from src.models import weather\n",
    "# Utilities package\n",
    "from src.common import utils\n",
    "# Package for interpolating and estimating weather\n",
    "from src.analysis import weather_interpolator\n",
    "\n",
    "# Path from this notebook to the root directory\n",
    "root_path = os.path.normpath(root_path)\n",
    "# Path from root to the desired config file\n",
    "config_path_from_root = os.path.normpath('config/config.yml')\n",
    "# Defining path from this notebook to config file\n",
    "config_path = os.path.join(root_path, config_path_from_root)\n",
    "\n",
    "# Loading config file\n",
    "with open(config_path, 'r',  encoding='utf8') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Defining \"clear-output\" function to feed into logger\n",
    "def clear():\n",
    "    clear_output(wait=True)\n",
    "\n",
    "# Creates an instance of a logger class to log all that happens, optional (but encouraged).\n",
    "logger = utils.Logger(config, clear_function=None)\n",
    "\n",
    "config['statistics']['interpolation']['flights']['step'] = 600\n",
    "# Creates an instance of the weather interpolator\n",
    "interpolator = weather_interpolator.WeatherInterpolator(config, logger=logger)\n",
    "\n",
    "# Defining location of data\n",
    "flights_database = '../data/flight/KDEN_KSEA_2023-01-01_2023-01-31.sqlite'\n",
    "weather_database = '../data/weather/Weather-US_2022-12-31_2023-02-01.sqlite'\n",
    "\n",
    "# Path to file keeping track of already-loaded flights\n",
    "tracking_file = flights_database.replace('sqlite','txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/649.\n",
      "Time Elapsed: 1h 9m 45s.\n",
      "Estimate time to finish: 6h 27m 34s.\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "# Path to file keeping track of already-loaded flights\n",
    "tracking_file = flights_database.replace('sqlite', 'txt')\n",
    "\n",
    "flights_connection = sqlite3.connect(flights_database)\n",
    "weather_connection = sqlite3.connect(weather_database)\n",
    "# Declares a cursor to write to the database\n",
    "cursor = flights_connection.cursor()\n",
    "\n",
    "# Checking and loading the tracking_file\n",
    "if os.path.isfile(tracking_file):\n",
    "    with open(tracking_file, 'r') as f:\n",
    "        loaded_ids = f.read().split('\\n')\n",
    "        loaded_ids = [i for i in loaded_ids if i != '']\n",
    "else:\n",
    "    with open(tracking_file, 'w') as f:\n",
    "        loaded_ids = []\n",
    "\n",
    "# Runs a query to identify all the flight_ids available\n",
    "flight_ids = pd.read_sql_query(\"SELECT flight_id FROM flights;\", flights_connection).values[:,0]\n",
    "# Only care about the ids that have not been loaded yet.\n",
    "flight_ids = [f for f in flight_ids if f not in loaded_ids]\n",
    "\n",
    "# Loading the time threshold variable, which is the time interval that weather data will be loaded for each calculation.\n",
    "time_thresh = config['statistics']['interpolation']['weather']['time-thresh']\n",
    "lat_lon_thresh = config['statistics']['interpolation']['weather']['lat-lon-thresh']\n",
    "\n",
    "# The list of columns to be added to the new table to be created.\n",
    "new_columns = ['tmpf', 'air_pressure', 'air_density', 'clouds', 'sknt', 'severity']\n",
    "\n",
    "# If there is no record of loaded ids, we start from scratch\n",
    "if len(loaded_ids) == 0:\n",
    "    # Drop the table if it exists\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS optimal_state_vector_weather;\")\n",
    "\n",
    "    # Create the new table\n",
    "    create_table_query = f'''\n",
    "        CREATE TABLE optimal_state_vector_weather (\n",
    "            flight_id TEXT,\n",
    "            {\", \".join([f\"{col} REAL\" for col in new_columns])}\n",
    "        );\n",
    "    '''\n",
    "    # Create the new table if it doesn't exist\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "# Commits change to file\n",
    "flights_connection.commit()\n",
    "# Closing connections\n",
    "flights_connection.close()\n",
    "weather_connection.close()\n",
    "\n",
    "t_start_full = datetime.datetime.now()\n",
    "\n",
    "count = 0\n",
    "\n",
    "num_cores = os.cpu_count()\n",
    "\n",
    "def main_computation(i, flight_id):\n",
    "    flights_connection = sqlite3.connect(flights_database)\n",
    "    weather_connection = sqlite3.connect(weather_database)\n",
    "\n",
    "    # Finds minimum and maximum flight for current flight\n",
    "    min_time, max_time = pd.read_sql_query(f\"\"\"\n",
    "                                SELECT MIN(time) as min_time, MAX(time) as max_time\n",
    "                                FROM state_vectors\n",
    "                                JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                               \"\"\",\n",
    "                              flights_connection\n",
    "                              ).values[0]\n",
    "\n",
    "    # Finds the minimum and maximum latitudes for the current flight\n",
    "    min_latitude, max_latitude = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT MIN(lat) as min_lat, MAX(lat) as max_lat\n",
    "                                    FROM state_vectors\n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\"\n",
    "                                   \"\"\",\n",
    "                                  flights_connection\n",
    "                                  ).values[0]\n",
    "\n",
    "    # Finds the minimum and maximum longitudes for the current flight\n",
    "    min_longitude, max_longitude = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT MIN(lon) as min_lon, MAX(lon) as max_lon\n",
    "                                    FROM state_vectors\n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\"\n",
    "                                   \"\"\",\n",
    "                                  flights_connection\n",
    "                                  ).values[0]\n",
    "\n",
    "    # Adjusting time, lat and lon thresholds.\n",
    "    # Adds time threshold to time limits\n",
    "    min_time -= time_thresh\n",
    "    max_time += time_thresh\n",
    "\n",
    "    # Adds latitude and longitude threshold\n",
    "    range_latitude = max_latitude - min_latitude\n",
    "    range_longitude = max_longitude - min_longitude\n",
    "    min_latitude -= range_latitude*lat_lon_thresh\n",
    "    max_latitude += range_latitude*lat_lon_thresh\n",
    "    min_longitude -= range_longitude*lat_lon_thresh\n",
    "    max_longitude += range_longitude*lat_lon_thresh\n",
    "\n",
    "    # Loads the weather data corresponding to the flight\n",
    "    flight_weather_data = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT ws.lat, ws.lon, ws.elevation, ws.sigma, wd.*\n",
    "                                    FROM weather_data as wd\n",
    "                                    JOIN weather_stations as ws ON ws.station_id = wd.station_id\n",
    "                                    WHERE wd.time BETWEEN {min_time} AND {max_time};\n",
    "                                   \"\"\",\n",
    "                                   weather_connection\n",
    "                                    )\n",
    "\n",
    "    # Loads state vectors for the given flight\n",
    "\n",
    "    optimal_state_vectors = pd.read_sql_query(f\"\"\"\n",
    "        SELECT sv.*\n",
    "        FROM state_vectors AS sv\n",
    "        INNER JOIN (\n",
    "            SELECT of.flight_id\n",
    "            FROM flights AS fs\n",
    "            JOIN flights_aircraft AS fa ON fs.icao24 = fa.icao24\n",
    "            JOIN optimal_flights AS of ON fa.typecode = of.typecode\n",
    "            WHERE fs.flight_id = \"{flight_id}\"\n",
    "        ) AS optimal_flight_id ON sv.flight_id = optimal_flight_id.flight_id;\n",
    "        \"\"\",\n",
    "        flights_connection)\n",
    "\n",
    "    optimal_state_vectors['time'] = [min_time + time_thresh - i for i in range(len(optimal_state_vectors))]\n",
    "\n",
    "    # Computes the weather values for the current flight\n",
    "    optimal_state_vectors = interpolator.compute_flight_weather_quantities(new_columns, optimal_state_vectors, stations_data=flight_weather_data)\n",
    "\n",
    "    # Extract the directory and filename\n",
    "    directory, filename = os.path.split(flights_database)\n",
    "\n",
    "    # Modify the filename\n",
    "    # Insert 'optimal_' at the beginning and replace '.sqlite' with '_{flight_id}.csv'\n",
    "    filename = 'optimal_' + filename.replace('.sqlite', f'_{flight_id}.csv')\n",
    "\n",
    "    # Combine the directory and the modified filename\n",
    "    csv_file = os.path.join(directory, filename)\n",
    "    \n",
    "    optimal_state_vectors[['flight_id'] + new_columns].to_csv(csv_file)\n",
    "    \n",
    "    flights_connection.close()\n",
    "    weather_connection.close()\n",
    "    \n",
    "    time_iteration = datetime.datetime.now()\n",
    "    time_elapsed = (time_iteration - t_start_full).total_seconds()\n",
    "    if i == 0:\n",
    "        ETA = np.nan\n",
    "    else:\n",
    "        ETA = time_elapsed*len(flight_ids)/i - time_elapsed\n",
    "    clear_output(wait=True)\n",
    "    print(f'{i}/{len(flight_ids)}.')\n",
    "    print(f'Time Elapsed: {utils.format_time(time_elapsed)}.')\n",
    "    print(f'Estimate time to finish: {utils.format_time(ETA)}.')\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_cores) as executor:\n",
    "    futures = [executor.submit(main_computation, i, flight_id) for i, flight_id in enumerate(flight_ids)]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        try:\n",
    "            result = future.result()\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "# for i, flight_id in enumerate(flight_ids):\n",
    "#     main_computation(i, flight_id)\n",
    "    \n",
    "import os\n",
    "csv_files = ['../data/flight/' + f for f in os.listdir('../data/flight') if f.startswith('optimal_' + flights_database.split('/')[-1].replace('.sqlite','')) and f.endswith('.csv')]\n",
    "\n",
    "flights_connection = sqlite3.connect(flights_database)\n",
    "cursor = flights_connection.cursor()\n",
    "\n",
    "for file in csv_files:\n",
    "    optimal_state_vectors_weather = pd.read_csv(file, index_col=0)\n",
    "    clear_output(wait=True)\n",
    "    print(file)\n",
    "    for index, row in optimal_state_vectors_weather.iterrows():\n",
    "        # Preparing the data to be inserted\n",
    "        insert_data = tuple(row[col] for col in ['flight_id'] + new_columns)\n",
    "\n",
    "        # Creating query to insert new values\n",
    "        insert_query = f'''\n",
    "            INSERT INTO optimal_state_vector_weather (flight_id, {', '.join(new_columns)})\n",
    "            VALUES ({', '.join('?' * len(insert_data))})\n",
    "        '''\n",
    "        cursor.execute(insert_query, insert_data)\n",
    "    # Commiting changes to the database\n",
    "    flights_connection.commit()\n",
    "\n",
    "flights_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FlightStats",
   "language": "python",
   "name": "flightstats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
