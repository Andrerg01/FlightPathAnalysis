{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage of `src.analysis.weather_interpolator` module.\n",
    "\n",
    "This notebook outlies the basic usage of the `src.analysis.weather_interpolator` module. Used to interpolate weather conditions at any time, lon, lat, and elevation.\n",
    " \n",
    "**Requirements**\n",
    " - A csv with weather station data for the whole country for a given time interval\n",
    " \n",
    "**Helpful Links**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/11/09 08:59:44 : CSV Decoding data from tutorial_data/state_vectors_compressed.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# This variable should indicate the path from this Jupyter Notebook to the root directory of the repo.\n",
    "root_path = '../'\n",
    "# Adds the repo's root to the list of paths\n",
    "sys.path.append(root_path)\n",
    "\n",
    "# Package to read yml files\n",
    "import yaml\n",
    "# Package to handle file paths\n",
    "import os\n",
    "# Package to deal with DataFrames\n",
    "import pandas as pd\n",
    "# Package to plot stuff\n",
    "import matplotlib.pyplot as plt\n",
    "# Package for numerical and array handling\n",
    "import numpy as np\n",
    "\n",
    "# Function to clear output from jupyter notebook\n",
    "from IPython.display import clear_output\n",
    "# Package for compressing dataframes into file\n",
    "from src.data import compressors\n",
    "# Package for defining and fitting weather models\n",
    "from src.models import weather\n",
    "# Utilities package\n",
    "from src.common import utils\n",
    "# Package for interpolating and estimating weather\n",
    "from src.analysis import weather_interpolator\n",
    "\n",
    "root_path = os.path.normpath(root_path) # Path from this notebook to the root directory\n",
    "config_path_from_root = os.path.normpath('config/config_tutorial.yml') # Path from root to the desired config file\n",
    "config_path = os.path.join(root_path, config_path_from_root) # Defining path from this notebook to config file\n",
    "\n",
    "# Loading config file\n",
    "with open(config_path, 'r',  encoding='utf8') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Defining \"clear-output\" function to feed into logger\n",
    "def clear():\n",
    "    clear_output(wait=True)\n",
    "\n",
    "# Creates an instance of a logger class to log all that happens, optional (but encouraged).\n",
    "logger = utils.Logger(config, clear_function=None)\n",
    "\n",
    "# Creates an isntance of the CsvCompressor\n",
    "compressor = compressors.CsvCompressor(config, logger=logger)\n",
    "\n",
    "# Creates an instance of the weather interpolator\n",
    "interpolator = weather_interpolator.WeatherInterpolator(config, logger=logger)\n",
    "\n",
    "# Defining location of data\n",
    "data_directory = 'tutorial_data'\n",
    "\n",
    "# Loading weather station data\n",
    "all_stations_data = pd.read_csv(os.path.join(data_directory, 'all_stations_data.csv'), index_col = 0)\n",
    "\n",
    "# Loading flight state_vectors\n",
    "state_vectors = compressor.decode_to_dataframe_from_file(os.path.join(data_directory, 'state_vectors_compressed.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolating weather at specific time, lat, lon, and elevation\n",
    "\n",
    "By Default, the interpolator will look for data in the weather's out-dir as specified in the config file, unless it's given one directly.\n",
    "\n",
    "The interpolator will also calibrate the weather data, unless specified that it has already beed calibrated as an argument\n",
    "\n",
    "Weather model calibration happens inside the estimation function.\n",
    "\n",
    "Target needs to be a dictionary with the necessary parameters, in this case we'll use the avegate values form the weather stations info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating scalar at given target location and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = {'lon': all_stations_data['lon'].mean(),\n",
    "         'lat': all_stations_data['lat'].mean(),\n",
    "         'timestamp': all_stations_data['timestamp'].mean(),\n",
    "         'elevation': all_stations_data['elevation'].mean(),\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31.62074063])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "interpolator.estimate_scalars(target, ['tmpf'], stations_data=all_stations_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([967.59686566])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "interpolator.estimate_scalars(target, ['air_pressure'], stations_data=all_stations_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.23501164])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "interpolator.estimate_scalars(target, ['air_density'], stations_data=all_stations_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "interpolator.estimate_scalars(target, ['clouds'], stations_data=all_stations_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 31.62074063, 967.59686566,   1.23501164,   0.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "interpolator.estimate_scalars(target, ['tmpf', 'air_pressure', 'air_density', 'clouds'], stations_data=all_stations_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/11/09 08:59:47 : CSV Decoding data from ../data/flight/KLAX_KSFO/state_vectors/71be29_1674543810_1674547109_KLAX_KSFO.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sv = compressor.decode_to_dataframe_from_file('../data/flight/KLAX_KSFO/state_vectors/71be29_1674543810_1674547109_KLAX_KSFO.csv')\n",
    "\n",
    "interpolator.estimate_flight_wind(sv)\n",
    "\n",
    "sv = interpolator.compute_flight_weather_quantities(['tmpf', 'air_pressure', 'air_density', 'clouds'], sv, stations_data=all_stations_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolator.load_relevant_files([sv.iloc[0]['time'], sv.iloc[-1]['time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"1671926400_1672531200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# scalars = ['tmpf', 'air_pressure', 'air_density', 'clouds']\n",
    "# scalar_values = {scalar: np.repeat(np.nan, len(state_vectors)) for scalar in scalars}\n",
    "# step = config['statistics']['interpolation']['flights']['step']\n",
    "# for i, row in state_vectors.iloc[::step].iterrows():\n",
    "#     clear()\n",
    "#     print(f'{i}/{len(state_vectors)}')\n",
    "#     target = {\n",
    "#         'lon': row['lon'],\n",
    "#         'lat': row['lat'],\n",
    "#         'timestamp': row['time'],\n",
    "#         'elevation': row['geoaltitude'],\n",
    "#          }\n",
    "#     values = interpolator.estimate_scalars(target, scalars, stations_data=all_stations_data)\n",
    "#     for j, scalar in enumerate(scalars):\n",
    "#         scalar_values[scalar][i] = values[j]\n",
    "# for scalar in scalars:\n",
    "#     state_vectors[scalar] = scalar_values[scalar]\n",
    "#     state_vectors[scalar] = state_vectors[scalar].interpolate(method='linear')\n",
    "\n",
    "# state_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'geolatitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/FlightStats/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'geolatitude'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m compressed \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtutorial_data/state_vectors_compressed.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m compressed[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeolatitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mplot()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/FlightStats/lib/python3.11/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/FlightStats/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'geolatitude'"
     ]
    }
   ],
   "source": [
    "compressed = pd.read_csv('tutorial_data/state_vectors_compressed.csv', index_col = 0)\n",
    "compressed['geolatitude'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "large_df = None\n",
    "path = '../data/flight/KDEN_KSEA/state_vectors/'\n",
    "files = [path + f for f in os.listdir(path) if f.endswith('.csv')]\n",
    "for file in files:\n",
    "    temp_df = pd.read_csv(file, index_col = 0)\n",
    "    temp_df['icao24'] = [file.split('/')[-1].split('_')[0]]*len(temp_df)\n",
    "    if large_df is None:\n",
    "        large_df = temp_df.copy()\n",
    "    else:\n",
    "        large_df = pd.concat([large_df, temp_df.copy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_df.to_csv('../data/flight/KDEN_KSEA/all_flights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FlightStats",
   "language": "python",
   "name": "flightstats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
