{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage of `src.analysis.weather_interpolator` module.\n",
    "\n",
    "This notebook outlies the basic usage of the `src.analysis.weather_interpolator` module. Used to interpolate weather conditions at any time, lon, lat, and elevation.\n",
    " \n",
    "**Requirements**\n",
    " - A csv with weather station data for the whole country for a given time interval\n",
    " \n",
    "**Helpful Links**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# This variable should indicate the path from this Jupyter Notebook to the root directory of the repo.\n",
    "root_path = '../'\n",
    "# Adds the repo's root to the list of paths\n",
    "sys.path.append(root_path)\n",
    "\n",
    "# Package to read yml files\n",
    "import yaml\n",
    "# Package to handle file paths\n",
    "import os\n",
    "# Package to deal with DataFrames\n",
    "import pandas as pd\n",
    "# Package to plot stuff\n",
    "import matplotlib.pyplot as plt\n",
    "# Package for numerical and array handling\n",
    "import numpy as np\n",
    "#\n",
    "import sqlite3\n",
    "\n",
    "# Function to clear output from jupyter notebook\n",
    "from IPython.display import clear_output\n",
    "# Package for compressing dataframes into file\n",
    "from src.data import compressors\n",
    "# Package for defining and fitting weather models\n",
    "from src.models import weather\n",
    "# Utilities package\n",
    "from src.common import utils\n",
    "# Package for interpolating and estimating weather\n",
    "from src.analysis import weather_interpolator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "root_path = os.path.normpath(root_path) # Path from this notebook to the root directory\n",
    "config_path_from_root = os.path.normpath('config/config_tutorial.yml') # Path from root to the desired config file\n",
    "config_path = os.path.join(root_path, config_path_from_root) # Defining path from this notebook to config file\n",
    "\n",
    "# Loading config file\n",
    "with open(config_path, 'r',  encoding='utf8') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Defining \"clear-output\" function to feed into logger\n",
    "def clear():\n",
    "    clear_output(wait=True)\n",
    "\n",
    "# Creates an instance of a logger class to log all that happens, optional (but encouraged).\n",
    "logger = utils.Logger(config, clear_function=None)\n",
    "\n",
    "# Creates an instance of the weather interpolator\n",
    "interpolator = weather_interpolator.WeatherInterpolator(config, logger=logger)\n",
    "\n",
    "# Defining location of data\n",
    "flights_database = '../data/flight/KDEN_KSEA_2023-01-01_2023-01-31.sqlite'\n",
    "weather_database = '../data/weather/1673827200_1685923200.sqlite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolating weather at specific time, lat, lon, and elevation\n",
    "\n",
    "By Default, the interpolator will look for data in the weather's out-dir as specified in the config file, unless it's given one directly.\n",
    "\n",
    "The interpolator will also calibrate the weather data, unless specified that it has already beed calibrated as an argument\n",
    "\n",
    "Weather model calibration happens inside the estimation function.\n",
    "\n",
    "Target needs to be a dictionary with the necessary parameters, in this case we'll use the avegate values form the weather stations info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating scalar at given target location and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_connection = sqlite3.connect(flights_database)\n",
    "weather_connection = sqlite3.connect(weather_database)\n",
    "\n",
    "flight_id = pd.read_sql_query(\"SELECT flight_id FROM flights ORDER BY RANDOM() LIMIT 1;\", flights_connection).values[0, 0]\n",
    "\n",
    "mean_time, max_time, min_time = pd.read_sql_query(f\"\"\"\n",
    "                                SELECT AVG(time) as avg_time, MAX(time) as max_time, MIN(time) as min_time\n",
    "                                FROM state_vectors \n",
    "                                JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                               \"\"\",\n",
    "                              flights_connection\n",
    "                              ).values[0]\n",
    "\n",
    "mean_latitude, max_latitude, min_latitude = pd.read_sql_query(f\"\"\"\n",
    "                                SELECT AVG(lat) as avg_lat, MAX(lat) as max_lat, MIN(lat) as min_lat\n",
    "                                FROM state_vectors \n",
    "                                JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                               \"\"\",\n",
    "                              flights_connection\n",
    "                              ).values[0]\n",
    "\n",
    "mean_longitude, max_longitude, min_longitude = pd.read_sql_query(f\"\"\"\n",
    "                                SELECT AVG(lon) as avg_lon, MAX(lon) as max_lon, MIN(lon) as min_lon\n",
    "                                FROM state_vectors \n",
    "                                JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                               \"\"\",\n",
    "                              flights_connection\n",
    "                              ).values[0]\n",
    "\n",
    "mean_geoaltitude = pd.read_sql_query(f\"\"\"\n",
    "                                SELECT AVG(geoaltitude) as avg_geoaltitude\n",
    "                                FROM state_vectors \n",
    "                                JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                               \"\"\",\n",
    "                              flights_connection\n",
    "                              ).values[0, 0]\n",
    "\n",
    "target = {'lon': mean_longitude,\n",
    "         'lat': mean_latitude,\n",
    "         'time': mean_time,\n",
    "         'elevation': mean_geoaltitude,\n",
    "         }\n",
    "\n",
    "time_thresh = config['statistics']['interpolation']['weather']['time-thresh']\n",
    "min_time -= time_thresh\n",
    "max_time += time_thresh\n",
    "\n",
    "latitude_range = max_latitude - min_latitude\n",
    "longitude_range = max_longitude - min_longitude\n",
    "\n",
    "max_latitude += latitude_range*0.1\n",
    "min_latitude -= latitude_range*0.1\n",
    "max_longitude += longitude_range*0.1\n",
    "min_longitude -= longitude_range*0.1\n",
    "\n",
    "flight_weather_data = pd.read_sql_query(f\"\"\"\n",
    "                                SELECT ws.lat, ws.lon, ws.elevation, ws.sigma, wd.*\n",
    "                                FROM weather_data as wd\n",
    "                                JOIN weather_stations as ws ON ws.station_id = wd.station_id\n",
    "                                WHERE wd.time BETWEEN {min_time} AND {max_time}\n",
    "                                AND ws.lat BETWEEN {min_latitude} AND {max_latitude}\n",
    "                                AND ws.lon BETWEEN {min_longitude} AND {max_longitude};\n",
    "                               \"\"\",\n",
    "                               weather_connection\n",
    "                                )\n",
    "\n",
    "state_vectors = pd.read_sql_query(f\"\"\"\n",
    "                                SELECT DISTINCT state_vectors.*\n",
    "                                FROM state_vectors \n",
    "                                JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                               \"\"\",\n",
    "                               flights_connection)\n",
    "# query\n",
    "\n",
    "flights_connection.close()\n",
    "weather_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flight_weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "interpolator.estimate_scalars(target, ['tmpf'], stations_data=flight_weather_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "interpolator.estimate_scalars(target, ['air_pressure'], stations_data=flight_weather_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "interpolator.estimate_scalars(target, ['air_density'], stations_data=flight_weather_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "interpolator.estimate_scalars(target, ['clouds'], stations_data=flight_weather_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "interpolator.estimate_scalars(target, ['severity'], stations_data=flight_weather_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "target = {\n",
    "    'lon': state_vectors.iloc[0]['lon'],\n",
    "    'lat': state_vectors.iloc[0]['lat'],\n",
    "    'time': state_vectors.iloc[0]['time'],\n",
    "    'elevation': state_vectors.iloc[0]['geoaltitude']\n",
    "}\n",
    "interpolator.estimate_scalars(target, ['tmpf', 'air_pressure', 'air_density', 'clouds', 'sknt', 'severity'], stations_data=flight_weather_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "state_vectors = interpolator.compute_flight_weather_quantities(['tmpf', 'air_pressure', 'air_density', 'clouds', 'sknt', 'severity'], state_vectors, stations_data=flight_weather_data, debug=False)\n",
    "state_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flight_ids)*(1*60 + 24)/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping thorugh flight_ids and computing weather\n",
    "\n",
    "This code also creates a new state_vector_weather table to save the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_connection = sqlite3.connect(flights_database)\n",
    "weather_connection = sqlite3.connect(weather_database)\n",
    "\n",
    "flight_ids = pd.read_sql_query(\"SELECT flight_id FROM flights;\", flights_connection).values[:,0]\n",
    "time_thresh = config['statistics']['interpolation']['weather']['time-thresh']\n",
    "\n",
    "new_columns = ['tmpf', 'air_pressure', 'air_density', 'clouds', 'sknt', 'severity']\n",
    "\n",
    "cursor = flights_connection.cursor()\n",
    "\n",
    "# Create the new table if it doesn't exist\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS state_vector_weather (\n",
    "        vector_id INTEGER PRIMARY KEY,\n",
    "        tmpf REAL, \n",
    "        air_pressure REAL, \n",
    "        air_density REAL, \n",
    "        clouds REAL, \n",
    "        sknt REAL,\n",
    "        severity REAL,\n",
    "    );\n",
    "''')\n",
    "flights_connection.commit()\n",
    "\n",
    "for i, flight_id in enumerate(flight_ids):\n",
    "    clear_output(wait=True)\n",
    "    print(f'{flight_id} | {i}/{len(flight_ids)}')\n",
    "\n",
    "    print('Loading time limits')\n",
    "    max_time, min_time = pd.read_sql_query(f\"\"\"\n",
    "                                SELECT MAX(time) as max_time, MIN(time) as min_time\n",
    "                                FROM state_vectors \n",
    "                                JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                               \"\"\",\n",
    "                              flights_connection\n",
    "                              ).values[0]\n",
    "    \n",
    "    min_time -= time_thresh\n",
    "    max_time += time_thresh\n",
    "\n",
    "    print('Loading relevant weather data')\n",
    "    flight_weather_data = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT ws.lat, ws.lon, ws.elevation, ws.sigma, wd.*\n",
    "                                    FROM weather_data as wd\n",
    "                                    JOIN weather_stations as ws ON ws.station_id = wd.station_id\n",
    "                                    WHERE wd.time BETWEEN {min_time} AND {max_time};\n",
    "                                   \"\"\",\n",
    "                                   weather_connection\n",
    "                                    )\n",
    "\n",
    "    print('Loading state vectors')\n",
    "    state_vectors = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT DISTINCT state_vectors.*\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                                   \"\"\",\n",
    "                                   flights_connection)\n",
    "    \n",
    "    print('Computing weather values')\n",
    "    state_vectors = interpolator.compute_flight_weather_quantities(['tmpf', 'air_pressure', 'air_density', 'clouds', 'sknt', 'severity'], state_vectors, stations_data=flight_weather_data)\n",
    "    \n",
    "    print('Adding new columns')\n",
    "    for col in new_columns:\n",
    "        try:\n",
    "            print(f\"Attempting to add column '{col}' to 'state_vectors'.\")\n",
    "            cursor.execute(f\"ALTER TABLE state_vectors ADD COLUMN {col} REAL;\")\n",
    "            flights_connection.commit()\n",
    "            print(f\"Column '{col}' added successfully.\")\n",
    "        except sqlite3.OperationalError as e:\n",
    "            print(f\"Error adding column '{col}': {e}\")\n",
    "            # If the error message is not about the column existing, re-raise the exception\n",
    "            if not 'duplicate column name' in str(e).lower():\n",
    "                raise\n",
    "            else:\n",
    "                print(f\"Column '{col}' already exists.\")\n",
    "    \n",
    "    print(\"Adding newly calculated values\")\n",
    "    for index, row in state_vectors.iterrows():\n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO state_vector_weather (vector_id, tmpf, air_pressure, air_density, clouds, sknt, severity) \n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "            ON CONFLICT(vector_id) DO UPDATE SET\n",
    "            tmpf = excluded.tmpf, \n",
    "            air_pressure = excluded.air_pressure,\n",
    "            air_density = excluded.air_density, \n",
    "            clouds = excluded.clouds, \n",
    "            sknt = excluded.sknt,\n",
    "            severity = excluded.severity;\n",
    "        \"\"\"\n",
    "        cursor.execute(insert_query, (row['vector_id'], row['tmpf'], row['air_pressure'], row['air_density'], row['clouds'], row['sknt'], row['severity']))\n",
    "    flights_connection.commit()\n",
    "# Commit the transaction after all updates\n",
    "\n",
    "flights_connection.close()\n",
    "weather_connection.close()\n",
    "# Save database that now has the new columns somehow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Integrate_Clouds(state_vectors):\n",
    "    return np.sum(state_vectors['clouds'].values)/(state_vectors['time'].values[-1] - state_vectors['time'].values[0])\n",
    "\n",
    "def Integrate_Wind_Speed(state_vectors):\n",
    "    return np.sum(state_vectors['sknt'].values)/(state_vectors['time'].values[-1] - state_vectors['time'].values[0])\n",
    "\n",
    "def Integrate_Path_Lenght(state_vectors):\n",
    "    # Computes xy displacements\n",
    "    dxy = np.array([utils.haversine_distance(row_a.lat, row_a.lon, row_b.lat, row_b.lon) for row_a, row_b in zip(state_vectors[:-1].itertuples(), state_vectors[1:].itertuples())])\n",
    "    # Computes z displacement\n",
    "    dz = np.array([np.abs(row_a.geoaltitude - row_b.geoaltitude) for row_a, row_b in zip(state_vectors[:-1].itertuples(), state_vectors[1:].itertuples())])\n",
    "    # Compute displacements\n",
    "    dr = np.sqrt(dxy**2 + dz**2)\n",
    "    \n",
    "    # Integrates\n",
    "    return np.sum(dr)\n",
    "\n",
    "def Integrate_Time(state_vectors):\n",
    "    return (state_vectors['time'].values[-1] - state_vectors['time'].values[0])\n",
    "\n",
    "\n",
    "for i, flight_id in enumerate(flight_ids):\n",
    "    flights_connection = sqlite3.connect(flights_database)\n",
    "\n",
    "    state_vectors = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT DISTINCT sv.*, svw.tmpf, svw.air_pressure, svw.air_density, svw.clouds, svw.sknt\n",
    "                                    FROM state_vectors AS sv\n",
    "                                    JOIN flights ON flights.flight_id = sv.flight_id\n",
    "                                    LEFT JOIN state_vector_weather AS svw ON sv.vector_id = svw.vector_id\n",
    "                                    WHERE sv.flight_id = \"{flight_id}\";\n",
    "                                   \"\"\",\n",
    "                                   flights_connection).dropna(axis = 'columns')\n",
    "\n",
    "    flights_connection.close()\n",
    "\n",
    "    integral = Integrate_Path_Lenght(state_vectors)\n",
    "\n",
    "    print(f'{flight_id} | {i}/{len(flight_ids)} | Path integral: {integral}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# scalars = ['tmpf', 'air_pressure', 'air_density', 'clouds']\n",
    "# scalar_values = {scalar: np.repeat(np.nan, len(state_vectors)) for scalar in scalars}\n",
    "# step = config['statistics']['interpolation']['flights']['step']\n",
    "# for i, row in state_vectors.iloc[::step].iterrows():\n",
    "#     clear()\n",
    "#     print(f'{i}/{len(state_vectors)}')\n",
    "#     target = {\n",
    "#         'lon': row['lon'],\n",
    "#         'lat': row['lat'],\n",
    "#         'timestamp': row['time'],\n",
    "#         'elevation': row['geoaltitude'],\n",
    "#          }\n",
    "#     values = interpolator.estimate_scalars(target, scalars, stations_data=all_stations_data)\n",
    "#     for j, scalar in enumerate(scalars):\n",
    "#         scalar_values[scalar][i] = values[j]\n",
    "# for scalar in scalars:\n",
    "#     state_vectors[scalar] = scalar_values[scalar]\n",
    "#     state_vectors[scalar] = state_vectors[scalar].interpolate(method='linear')\n",
    "\n",
    "# state_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compressed = pd.read_csv('tutorial_data/state_vectors_compressed.csv', index_col = 0)\n",
    "# compressed['geolatitude'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# large_df = None\n",
    "# path = '../data/flight/KDEN_KSEA/state_vectors/'\n",
    "# files = [path + f for f in os.listdir(path) if f.endswith('.csv')]\n",
    "# for file in files:\n",
    "#     temp_df = pd.read_csv(file, index_col = 0)\n",
    "#     temp_df['icao24'] = [file.split('/')[-1].split('_')[0]]*len(temp_df)\n",
    "#     if large_df is None:\n",
    "#         large_df = temp_df.copy()\n",
    "#     else:\n",
    "#         large_df = pd.concat([large_df, temp_df.copy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large_df.to_csv('../data/flight/KDEN_KSEA/all_flights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flights_connection = sqlite3.connect(flights_database)\n",
    "# cursor = flights_connection.cursor()\n",
    "\n",
    "# # Create a new table with unique entries\n",
    "# cursor.execute('''\n",
    "# CREATE TABLE unique_state_vectors AS \n",
    "# SELECT * FROM state_vectors \n",
    "# GROUP BY vector_id;\n",
    "# ''')\n",
    "\n",
    "# flights_connection.commit()\n",
    "\n",
    "# # Drop the old table\n",
    "# cursor.execute('DROP TABLE state_vectors;')\n",
    "\n",
    "# # Rename the new table to the original name\n",
    "# cursor.execute('ALTER TABLE unique_state_vectors RENAME TO state_vectors;')\n",
    "\n",
    "# flights_connection.commit()\n",
    "\n",
    "# flights_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flights_connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flights_connection = sqlite3.connect(flights_database)\n",
    "# cursor = flights_connection.cursor()\n",
    "\n",
    "# # SQL to create a new table with unique entries, keeping the most recent row for each vector_id\n",
    "# cursor.execute('''\n",
    "# CREATE TABLE unique_state_vectors AS \n",
    "# SELECT * \n",
    "# FROM state_vectors \n",
    "# WHERE rowid IN (\n",
    "#     SELECT MAX(rowid) \n",
    "#     FROM state_vectors \n",
    "#     GROUP BY vector_id\n",
    "# );\n",
    "# ''')\n",
    "\n",
    "# flights_connection.commit()\n",
    "\n",
    "# # Drop the old table\n",
    "# cursor.execute('DROP TABLE state_vectors;')\n",
    "\n",
    "# # Rename the new table to the original name\n",
    "# cursor.execute('ALTER TABLE unique_state_vectors RENAME TO state_vectors;')\n",
    "\n",
    "# flights_connection.commit()\n",
    "# flights_connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FlightStats",
   "language": "python",
   "name": "flightstats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
