{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Weather for Each Flight Route\n",
    "\n",
    "This notebook should have everything you need to compute the weather conditions selected for a given flight.\n",
    "\n",
    "To make this work, make sure you have the following done:\n",
    " - Rename the `config/config_template.yml` file as `config/config.yml`\n",
    " - Change the `base-configs - root-directory` entry to wherever you downloaded the project repo\n",
    " - Change the `base-configs - tag` entry to whatever you'd like to, I don't think it'll matter, but who knows\n",
    " - Make sure all the dependencies are installed with `pip install -r requirements.txt`\n",
    " - Change the `flights_database` and `weather_database` variables below to whatever flight one you assigned yourself to, and the corresponding weather\n",
    " - Have fun and pray for no bugs!\n",
    " - If you need to make an environment readable on Jupyter you can follow [this guide](https://medium.com/@nrk25693/how-to-add-your-conda-environment-to-your-jupyter-notebook-in-just-4-steps-abeab8b8d084). If not, just copy the code and make it into a script. Up to ya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# This variable should indicate the path from this Jupyter Notebook to the root directory of the repo.\n",
    "root_path = '../'\n",
    "# Adds the repo's root to the list of paths\n",
    "sys.path.append(root_path)\n",
    "\n",
    "# Package to read yml files\n",
    "import yaml\n",
    "# Package to handle file paths\n",
    "import os\n",
    "# Package to deal with DataFrames\n",
    "import pandas as pd\n",
    "# Package to plot stuff\n",
    "import matplotlib.pyplot as plt\n",
    "# Package for numerical and array handling\n",
    "import numpy as np\n",
    "# Package to read and write to .sqlite files\n",
    "import sqlite3\n",
    "# Package to keep track of time\n",
    "import datetime\n",
    "\n",
    "# Function to clear output from jupyter notebook\n",
    "from IPython.display import clear_output\n",
    "# Package for compressing dataframes into file\n",
    "from src.data import compressors\n",
    "# Package for defining and fitting weather models\n",
    "from src.models import weather\n",
    "# Utilities package\n",
    "from src.common import utils\n",
    "# Package for interpolating and estimating weather\n",
    "from src.analysis import weather_interpolator\n",
    "\n",
    "# Path from this notebook to the root directory\n",
    "root_path = os.path.normpath(root_path)\n",
    "# Path from root to the desired config file\n",
    "config_path_from_root = os.path.normpath('config/config.yml')\n",
    "# Defining path from this notebook to config file\n",
    "config_path = os.path.join(root_path, config_path_from_root)\n",
    "\n",
    "# Loading config file\n",
    "with open(config_path, 'r',  encoding='utf8') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Defining \"clear-output\" function to feed into logger\n",
    "def clear():\n",
    "    clear_output(wait=True)\n",
    "\n",
    "# Creates an instance of a logger class to log all that happens, optional (but encouraged).\n",
    "logger = utils.Logger(config, clear_function=None)\n",
    "\n",
    "# Creates an instance of the weather interpolator\n",
    "interpolator = weather_interpolator.WeatherInterpolator(config, logger=logger)\n",
    "\n",
    "# Defining location of data\n",
    "flights_database = '../data/flight/KDEN_KSEA_2023-07-01_2023-07-31.sqlite'\n",
    "weather_database = '../data/weather/Weather-US_2023-06-30_2022-08-01.sqlite'\n",
    "\n",
    "# Path to file keeping track of already-loaded flights\n",
    "tracking_file = flights_database.replace('sqlite','txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ac33a3_1690489043_1690497432_KDEN_KSEA | 822/823.\n",
      "Time Elapsed: 16h 43m 27s.\n",
      "Estimate time to finish: 1m 13s.\n",
      "Loading time limits.\n",
      "Loading latitude limits.\n",
      "Loading longitude limits.\n",
      "Adjusting time, lat, lon thresholds.\n",
      "Loading relevant weather data.\n",
      "Loading state vectors.\n",
      "Computing weather values.\n",
      "Adding newly calculated values to new table\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Declares the connections read from each of the databases\n",
    "flights_connection = sqlite3.connect(flights_database)\n",
    "weather_connection = sqlite3.connect(weather_database)\n",
    "# Declares a cursor to write to the database\n",
    "cursor = flights_connection.cursor()\n",
    "\n",
    "# Checking and loading the tracking_file\n",
    "if os.path.isfile(tracking_file):\n",
    "    with open(tracking_file, 'r') as f:\n",
    "        loaded_ids = f.read().split('\\n')\n",
    "        loaded_ids = [i for i in loaded_ids if i != '']\n",
    "else:\n",
    "    with open(tracking_file, 'w') as f:\n",
    "        loaded_ids = []\n",
    "    \n",
    "\n",
    "# Runs a query to identify all the flight_ids available\n",
    "flight_ids = pd.read_sql_query(\"SELECT flight_id FROM flights;\", flights_connection).values[:,0]\n",
    "# Only care about the ids that have not been loaded yet.\n",
    "flight_ids = [f for f in flight_ids if f not in loaded_ids]\n",
    "\n",
    "# Loading the time threshold variable, which is the time interval that weather data will be loaded for each calculation.\n",
    "time_thresh = config['statistics']['interpolation']['weather']['time-thresh']\n",
    "lat_lon_thresh = config['statistics']['interpolation']['weather']['lat-lon-thresh']\n",
    "\n",
    "# The list of columns to be added to the new table to be created.\n",
    "new_columns = ['tmpf', 'air_pressure', 'air_density', 'clouds', 'sknt', 'severity']\n",
    "\n",
    "# If there is no record of loaded ids, we start from scratch\n",
    "if len(loaded_ids) == 0:\n",
    "    # Drop the table if it exists\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS state_vector_weather;\")\n",
    "\n",
    "    # Create the new table\n",
    "    create_table_query = f'''\n",
    "        CREATE TABLE state_vector_weather (\n",
    "            vector_id INTEGER PRIMARY KEY,\n",
    "            {\", \".join([f\"{col} REAL\" for col in new_columns])}\n",
    "        );\n",
    "    '''\n",
    "    # Create the new table if it doesn't exist\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "# Commits change to file\n",
    "flights_connection.commit()\n",
    "\n",
    "t_start_full = datetime.datetime.now()\n",
    "# Looping through flight ids\n",
    "for i, flight_id in enumerate(flight_ids):\n",
    "    time_iteration = datetime.datetime.now()\n",
    "    # Clears output at every loop\n",
    "    clear_output(wait=True)\n",
    "    print(f'{flight_id} | {i}/{len(flight_ids)}.')\n",
    "    time_elapsed = (time_iteration - t_start_full).total_seconds()\n",
    "    if i == 0:\n",
    "        ETA = np.nan\n",
    "    else:\n",
    "        ETA = time_elapsed*len(flight_ids)/i - time_elapsed\n",
    "    print(f'Time Elapsed: {utils.format_time(time_elapsed)}.')\n",
    "    print(f'Estimate time to finish: {utils.format_time(ETA)}.')\n",
    "    \n",
    "    # Finds minimum and maximum flight for current flight\n",
    "    print('Loading time limits.')\n",
    "    min_time, max_time = pd.read_sql_query(f\"\"\"\n",
    "                                SELECT MIN(time) as min_time, MAX(time) as max_time\n",
    "                                FROM state_vectors \n",
    "                                JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                               \"\"\",\n",
    "                              flights_connection\n",
    "                              ).values[0]\n",
    "    \n",
    "    # Finds the minimum and maximum latitudes for the current flight\n",
    "    print('Loading latitude limits.')\n",
    "    min_latitude, max_latitude = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT MIN(lat) as min_lat, MAX(lat) as max_lat\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\"\n",
    "                                   \"\"\",\n",
    "                                  flights_connection\n",
    "                                  ).values[0]\n",
    "\n",
    "    print('Loading longitude limits.')\n",
    "    # Finds the minimum and maximum longitudes for the current flight\n",
    "    min_longitude, max_longitude = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT MIN(lon) as min_lon, MAX(lon) as max_lon\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\"\n",
    "                                   \"\"\",\n",
    "                                  flights_connection\n",
    "                                  ).values[0]\n",
    "    \n",
    "    # Adjusting time, lat and lon thresholds.\n",
    "    print(\"Adjusting time, lat, lon thresholds.\")\n",
    "    # Adds time threshold to time limits\n",
    "    min_time -= time_thresh\n",
    "    max_time += time_thresh\n",
    "    \n",
    "    # Adds latitude and longitude threshold\n",
    "    range_latitude = max_latitude - min_latitude\n",
    "    range_longitude = max_longitude - min_longitude\n",
    "    min_latitude -= range_latitude*lat_lon_thresh\n",
    "    max_latitude += range_latitude*lat_lon_thresh\n",
    "    min_longitude -= range_longitude*lat_lon_thresh\n",
    "    max_longitude += range_longitude*lat_lon_thresh    \n",
    "    \n",
    "    # Loads the weather data corresponding to the flight\n",
    "    print('Loading relevant weather data.')\n",
    "    flight_weather_data = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT ws.lat, ws.lon, ws.elevation, ws.sigma, wd.*\n",
    "                                    FROM weather_data as wd\n",
    "                                    JOIN weather_stations as ws ON ws.station_id = wd.station_id\n",
    "                                    WHERE wd.time BETWEEN {min_time} AND {max_time};\n",
    "                                   \"\"\",\n",
    "                                   weather_connection\n",
    "                                    )\n",
    "\n",
    "    # Loads state vectors for the given flight\n",
    "    print('Loading state vectors.')\n",
    "    state_vectors = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT DISTINCT state_vectors.*\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                                   \"\"\",\n",
    "                                   flights_connection)\n",
    "    \n",
    "    # Computes the weather values for the current flight\n",
    "    print('Computing weather values.')\n",
    "    state_vectors = interpolator.compute_flight_weather_quantities(new_columns, state_vectors, stations_data=flight_weather_data)\n",
    "    \n",
    "    # Adds newly calculated values to new table    \n",
    "    print(\"Adding newly calculated values to new table\")\n",
    "    for index, row in state_vectors.iterrows():\n",
    "        # Preparing the data to be inserted\n",
    "        insert_data = tuple(row[col] for col in ['vector_id'] + new_columns)\n",
    "\n",
    "        # Creating query to insert new values\n",
    "        insert_query = f'''\n",
    "            INSERT INTO state_vector_weather (vector_id, {', '.join(new_columns)})\n",
    "            VALUES ({', '.join('?' * len(insert_data))})\n",
    "            ON CONFLICT(vector_id) DO UPDATE SET\n",
    "            {', '.join([f\"{col} = excluded.{col}\" for col in new_columns])};\n",
    "        '''\n",
    "        cursor.execute(insert_query, insert_data)\n",
    "    # Commiting changes to the database\n",
    "    flights_connection.commit()\n",
    "    \n",
    "    with open(tracking_file, 'a') as f:\n",
    "        f.write(flight_id + '\\n')\n",
    "\n",
    "# Closing connections\n",
    "flights_connection.close()\n",
    "weather_connection.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# This variable should indicate the path from this Jupyter Notebook to the root directory of the repo.\n",
    "root_path = '../'\n",
    "# Adds the repo's root to the list of paths\n",
    "sys.path.append(root_path)\n",
    "\n",
    "# Package to read yml files\n",
    "import yaml\n",
    "# Package to handle file paths\n",
    "import os\n",
    "# Package to deal with DataFrames\n",
    "import pandas as pd\n",
    "# Package to plot stuff\n",
    "import matplotlib.pyplot as plt\n",
    "# Package for numerical and array handling\n",
    "import numpy as np\n",
    "# Package to read and write to .sqlite files\n",
    "import sqlite3\n",
    "# Package to keep track of time\n",
    "import datetime\n",
    "\n",
    "# Function to clear output from jupyter notebook\n",
    "from IPython.display import clear_output\n",
    "# Package for compressing dataframes into file\n",
    "from src.data import compressors\n",
    "# Package for defining and fitting weather models\n",
    "from src.models import weather\n",
    "# Utilities package\n",
    "from src.common import utils\n",
    "# Package for interpolating and estimating weather\n",
    "from src.analysis import weather_interpolator\n",
    "\n",
    "# Path from this notebook to the root directory\n",
    "root_path = os.path.normpath(root_path)\n",
    "# Path from root to the desired config file\n",
    "config_path_from_root = os.path.normpath('config/config.yml')\n",
    "# Defining path from this notebook to config file\n",
    "config_path = os.path.join(root_path, config_path_from_root)\n",
    "\n",
    "# Loading config file\n",
    "with open(config_path, 'r',  encoding='utf8') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Defining \"clear-output\" function to feed into logger\n",
    "def clear():\n",
    "    clear_output(wait=True)\n",
    "\n",
    "# Creates an instance of a logger class to log all that happens, optional (but encouraged).\n",
    "logger = utils.Logger(config, clear_function=None)\n",
    "\n",
    "# Creates an instance of the weather interpolator\n",
    "interpolator = weather_interpolator.WeatherInterpolator(config, logger=logger)\n",
    "\n",
    "# Defining location of data\n",
    "flights_database = '../data/flight/KJFK_KLAX_2023-07-01_2023-07-31.sqlite'\n",
    "weather_database = '../data/weather/Weather-US_2023-06-30_2022-08-01.sqlite'\n",
    "\n",
    "# Path to file keeping track of already-loaded flights\n",
    "tracking_file = flights_database.replace('sqlite','txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a12c18_1690481880_1690500176_KJFK_KLAX | 998/999.\n",
      "Time Elapsed: 1d 3h 53m 49s.\n",
      "Estimate time to finish: 1m 40s.\n",
      "Loading time limits.\n",
      "Loading latitude limits.\n",
      "Loading longitude limits.\n",
      "Adjusting time, lat, lon thresholds.\n",
      "Loading relevant weather data.\n",
      "Loading state vectors.\n",
      "Computing weather values.\n",
      "Adding newly calculated values to new table\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Declares the connections read from each of the databases\n",
    "flights_connection = sqlite3.connect(flights_database)\n",
    "weather_connection = sqlite3.connect(weather_database)\n",
    "# Declares a cursor to write to the database\n",
    "cursor = flights_connection.cursor()\n",
    "\n",
    "# Checking and loading the tracking_file\n",
    "if os.path.isfile(tracking_file):\n",
    "    with open(tracking_file, 'r') as f:\n",
    "        loaded_ids = f.read().split('\\n')\n",
    "        loaded_ids = [i for i in loaded_ids if i != '']\n",
    "else:\n",
    "    with open(tracking_file, 'w') as f:\n",
    "        loaded_ids = []\n",
    "    \n",
    "\n",
    "# Runs a query to identify all the flight_ids available\n",
    "flight_ids = pd.read_sql_query(\"SELECT flight_id FROM flights;\", flights_connection).values[:,0]\n",
    "# Only care about the ids that have not been loaded yet.\n",
    "flight_ids = [f for f in flight_ids if f not in loaded_ids]\n",
    "\n",
    "# Loading the time threshold variable, which is the time interval that weather data will be loaded for each calculation.\n",
    "time_thresh = config['statistics']['interpolation']['weather']['time-thresh']\n",
    "lat_lon_thresh = config['statistics']['interpolation']['weather']['lat-lon-thresh']\n",
    "\n",
    "# The list of columns to be added to the new table to be created.\n",
    "new_columns = ['tmpf', 'air_pressure', 'air_density', 'clouds', 'sknt', 'severity']\n",
    "\n",
    "# If there is no record of loaded ids, we start from scratch\n",
    "if len(loaded_ids) == 0:\n",
    "    # Drop the table if it exists\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS state_vector_weather;\")\n",
    "\n",
    "    # Create the new table\n",
    "    create_table_query = f'''\n",
    "        CREATE TABLE state_vector_weather (\n",
    "            vector_id INTEGER PRIMARY KEY,\n",
    "            {\", \".join([f\"{col} REAL\" for col in new_columns])}\n",
    "        );\n",
    "    '''\n",
    "    # Create the new table if it doesn't exist\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "# Commits change to file\n",
    "flights_connection.commit()\n",
    "\n",
    "t_start_full = datetime.datetime.now()\n",
    "# Looping through flight ids\n",
    "for i, flight_id in enumerate(flight_ids):\n",
    "    time_iteration = datetime.datetime.now()\n",
    "    # Clears output at every loop\n",
    "    clear_output(wait=True)\n",
    "    print(f'{flight_id} | {i}/{len(flight_ids)}.')\n",
    "    time_elapsed = (time_iteration - t_start_full).total_seconds()\n",
    "    if i == 0:\n",
    "        ETA = np.nan\n",
    "    else:\n",
    "        ETA = time_elapsed*len(flight_ids)/i - time_elapsed\n",
    "    print(f'Time Elapsed: {utils.format_time(time_elapsed)}.')\n",
    "    print(f'Estimate time to finish: {utils.format_time(ETA)}.')\n",
    "    \n",
    "    # Finds minimum and maximum flight for current flight\n",
    "    print('Loading time limits.')\n",
    "    min_time, max_time = pd.read_sql_query(f\"\"\"\n",
    "                                SELECT MIN(time) as min_time, MAX(time) as max_time\n",
    "                                FROM state_vectors \n",
    "                                JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                               \"\"\",\n",
    "                              flights_connection\n",
    "                              ).values[0]\n",
    "    \n",
    "    # Finds the minimum and maximum latitudes for the current flight\n",
    "    print('Loading latitude limits.')\n",
    "    min_latitude, max_latitude = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT MIN(lat) as min_lat, MAX(lat) as max_lat\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\"\n",
    "                                   \"\"\",\n",
    "                                  flights_connection\n",
    "                                  ).values[0]\n",
    "\n",
    "    print('Loading longitude limits.')\n",
    "    # Finds the minimum and maximum longitudes for the current flight\n",
    "    min_longitude, max_longitude = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT MIN(lon) as min_lon, MAX(lon) as max_lon\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\"\n",
    "                                   \"\"\",\n",
    "                                  flights_connection\n",
    "                                  ).values[0]\n",
    "    \n",
    "    # Adjusting time, lat and lon thresholds.\n",
    "    print(\"Adjusting time, lat, lon thresholds.\")\n",
    "    # Adds time threshold to time limits\n",
    "    min_time -= time_thresh\n",
    "    max_time += time_thresh\n",
    "    \n",
    "    # Adds latitude and longitude threshold\n",
    "    range_latitude = max_latitude - min_latitude\n",
    "    range_longitude = max_longitude - min_longitude\n",
    "    min_latitude -= range_latitude*lat_lon_thresh\n",
    "    max_latitude += range_latitude*lat_lon_thresh\n",
    "    min_longitude -= range_longitude*lat_lon_thresh\n",
    "    max_longitude += range_longitude*lat_lon_thresh    \n",
    "    \n",
    "    # Loads the weather data corresponding to the flight\n",
    "    print('Loading relevant weather data.')\n",
    "    flight_weather_data = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT ws.lat, ws.lon, ws.elevation, ws.sigma, wd.*\n",
    "                                    FROM weather_data as wd\n",
    "                                    JOIN weather_stations as ws ON ws.station_id = wd.station_id\n",
    "                                    WHERE wd.time BETWEEN {min_time} AND {max_time};\n",
    "                                   \"\"\",\n",
    "                                   weather_connection\n",
    "                                    )\n",
    "\n",
    "    # Loads state vectors for the given flight\n",
    "    print('Loading state vectors.')\n",
    "    state_vectors = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT DISTINCT state_vectors.*\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                                   \"\"\",\n",
    "                                   flights_connection)\n",
    "    \n",
    "    # Computes the weather values for the current flight\n",
    "    print('Computing weather values.')\n",
    "    state_vectors = interpolator.compute_flight_weather_quantities(new_columns, state_vectors, stations_data=flight_weather_data)\n",
    "    \n",
    "    # Adds newly calculated values to new table    \n",
    "    print(\"Adding newly calculated values to new table\")\n",
    "    for index, row in state_vectors.iterrows():\n",
    "        # Preparing the data to be inserted\n",
    "        insert_data = tuple(row[col] for col in ['vector_id'] + new_columns)\n",
    "\n",
    "        # Creating query to insert new values\n",
    "        insert_query = f'''\n",
    "            INSERT INTO state_vector_weather (vector_id, {', '.join(new_columns)})\n",
    "            VALUES ({', '.join('?' * len(insert_data))})\n",
    "            ON CONFLICT(vector_id) DO UPDATE SET\n",
    "            {', '.join([f\"{col} = excluded.{col}\" for col in new_columns])};\n",
    "        '''\n",
    "        cursor.execute(insert_query, insert_data)\n",
    "    # Commiting changes to the database\n",
    "    flights_connection.commit()\n",
    "    \n",
    "    with open(tracking_file, 'a') as f:\n",
    "        f.write(flight_id + '\\n')\n",
    "\n",
    "# Closing connections\n",
    "flights_connection.close()\n",
    "weather_connection.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# This variable should indicate the path from this Jupyter Notebook to the root directory of the repo.\n",
    "root_path = '../'\n",
    "# Adds the repo's root to the list of paths\n",
    "sys.path.append(root_path)\n",
    "\n",
    "# Package to read yml files\n",
    "import yaml\n",
    "# Package to handle file paths\n",
    "import os\n",
    "# Package to deal with DataFrames\n",
    "import pandas as pd\n",
    "# Package to plot stuff\n",
    "import matplotlib.pyplot as plt\n",
    "# Package for numerical and array handling\n",
    "import numpy as np\n",
    "# Package to read and write to .sqlite files\n",
    "import sqlite3\n",
    "# Package to keep track of time\n",
    "import datetime\n",
    "\n",
    "# Function to clear output from jupyter notebook\n",
    "from IPython.display import clear_output\n",
    "# Package for compressing dataframes into file\n",
    "from src.data import compressors\n",
    "# Package for defining and fitting weather models\n",
    "from src.models import weather\n",
    "# Utilities package\n",
    "from src.common import utils\n",
    "# Package for interpolating and estimating weather\n",
    "from src.analysis import weather_interpolator\n",
    "\n",
    "# Path from this notebook to the root directory\n",
    "root_path = os.path.normpath(root_path)\n",
    "# Path from root to the desired config file\n",
    "config_path_from_root = os.path.normpath('config/config.yml')\n",
    "# Defining path from this notebook to config file\n",
    "config_path = os.path.join(root_path, config_path_from_root)\n",
    "\n",
    "# Loading config file\n",
    "with open(config_path, 'r',  encoding='utf8') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Defining \"clear-output\" function to feed into logger\n",
    "def clear():\n",
    "    clear_output(wait=True)\n",
    "\n",
    "# Creates an instance of a logger class to log all that happens, optional (but encouraged).\n",
    "logger = utils.Logger(config, clear_function=None)\n",
    "\n",
    "# Creates an instance of the weather interpolator\n",
    "interpolator = weather_interpolator.WeatherInterpolator(config, logger=logger)\n",
    "\n",
    "# Defining location of data\n",
    "flights_database = '../data/flight/KLAX_KJFK_2023-07-01_2023-07-31.sqlite'\n",
    "weather_database = '../data/weather/Weather-US_2023-06-30_2022-08-01.sqlite'\n",
    "\n",
    "# Path to file keeping track of already-loaded flights\n",
    "tracking_file = flights_database.replace('sqlite','txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a11380_1690482460_1690501195_KLAX_KJFK | 966/967.\n",
      "Time Elapsed: 1d 2h 7m 1s.\n",
      "Estimate time to finish: 1m 37s.\n",
      "Loading time limits.\n",
      "Loading latitude limits.\n",
      "Loading longitude limits.\n",
      "Adjusting time, lat, lon thresholds.\n",
      "Loading relevant weather data.\n",
      "Loading state vectors.\n",
      "Computing weather values.\n",
      "Adding newly calculated values to new table\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Declares the connections read from each of the databases\n",
    "flights_connection = sqlite3.connect(flights_database)\n",
    "weather_connection = sqlite3.connect(weather_database)\n",
    "# Declares a cursor to write to the database\n",
    "cursor = flights_connection.cursor()\n",
    "\n",
    "# Checking and loading the tracking_file\n",
    "if os.path.isfile(tracking_file):\n",
    "    with open(tracking_file, 'r') as f:\n",
    "        loaded_ids = f.read().split('\\n')\n",
    "        loaded_ids = [i for i in loaded_ids if i != '']\n",
    "else:\n",
    "    with open(tracking_file, 'w') as f:\n",
    "        loaded_ids = []\n",
    "    \n",
    "\n",
    "# Runs a query to identify all the flight_ids available\n",
    "flight_ids = pd.read_sql_query(\"SELECT flight_id FROM flights;\", flights_connection).values[:,0]\n",
    "# Only care about the ids that have not been loaded yet.\n",
    "flight_ids = [f for f in flight_ids if f not in loaded_ids]\n",
    "\n",
    "# Loading the time threshold variable, which is the time interval that weather data will be loaded for each calculation.\n",
    "time_thresh = config['statistics']['interpolation']['weather']['time-thresh']\n",
    "lat_lon_thresh = config['statistics']['interpolation']['weather']['lat-lon-thresh']\n",
    "\n",
    "# The list of columns to be added to the new table to be created.\n",
    "new_columns = ['tmpf', 'air_pressure', 'air_density', 'clouds', 'sknt', 'severity']\n",
    "\n",
    "# If there is no record of loaded ids, we start from scratch\n",
    "if len(loaded_ids) == 0:\n",
    "    # Drop the table if it exists\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS state_vector_weather;\")\n",
    "\n",
    "    # Create the new table\n",
    "    create_table_query = f'''\n",
    "        CREATE TABLE state_vector_weather (\n",
    "            vector_id INTEGER PRIMARY KEY,\n",
    "            {\", \".join([f\"{col} REAL\" for col in new_columns])}\n",
    "        );\n",
    "    '''\n",
    "    # Create the new table if it doesn't exist\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "# Commits change to file\n",
    "flights_connection.commit()\n",
    "\n",
    "t_start_full = datetime.datetime.now()\n",
    "# Looping through flight ids\n",
    "for i, flight_id in enumerate(flight_ids):\n",
    "    time_iteration = datetime.datetime.now()\n",
    "    # Clears output at every loop\n",
    "    clear_output(wait=True)\n",
    "    print(f'{flight_id} | {i}/{len(flight_ids)}.')\n",
    "    time_elapsed = (time_iteration - t_start_full).total_seconds()\n",
    "    if i == 0:\n",
    "        ETA = np.nan\n",
    "    else:\n",
    "        ETA = time_elapsed*len(flight_ids)/i - time_elapsed\n",
    "    print(f'Time Elapsed: {utils.format_time(time_elapsed)}.')\n",
    "    print(f'Estimate time to finish: {utils.format_time(ETA)}.')\n",
    "    \n",
    "    # Finds minimum and maximum flight for current flight\n",
    "    print('Loading time limits.')\n",
    "    min_time, max_time = pd.read_sql_query(f\"\"\"\n",
    "                                SELECT MIN(time) as min_time, MAX(time) as max_time\n",
    "                                FROM state_vectors \n",
    "                                JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                               \"\"\",\n",
    "                              flights_connection\n",
    "                              ).values[0]\n",
    "    \n",
    "    # Finds the minimum and maximum latitudes for the current flight\n",
    "    print('Loading latitude limits.')\n",
    "    min_latitude, max_latitude = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT MIN(lat) as min_lat, MAX(lat) as max_lat\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\"\n",
    "                                   \"\"\",\n",
    "                                  flights_connection\n",
    "                                  ).values[0]\n",
    "\n",
    "    print('Loading longitude limits.')\n",
    "    # Finds the minimum and maximum longitudes for the current flight\n",
    "    min_longitude, max_longitude = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT MIN(lon) as min_lon, MAX(lon) as max_lon\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\"\n",
    "                                   \"\"\",\n",
    "                                  flights_connection\n",
    "                                  ).values[0]\n",
    "    \n",
    "    # Adjusting time, lat and lon thresholds.\n",
    "    print(\"Adjusting time, lat, lon thresholds.\")\n",
    "    # Adds time threshold to time limits\n",
    "    min_time -= time_thresh\n",
    "    max_time += time_thresh\n",
    "    \n",
    "    # Adds latitude and longitude threshold\n",
    "    range_latitude = max_latitude - min_latitude\n",
    "    range_longitude = max_longitude - min_longitude\n",
    "    min_latitude -= range_latitude*lat_lon_thresh\n",
    "    max_latitude += range_latitude*lat_lon_thresh\n",
    "    min_longitude -= range_longitude*lat_lon_thresh\n",
    "    max_longitude += range_longitude*lat_lon_thresh    \n",
    "    \n",
    "    # Loads the weather data corresponding to the flight\n",
    "    print('Loading relevant weather data.')\n",
    "    flight_weather_data = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT ws.lat, ws.lon, ws.elevation, ws.sigma, wd.*\n",
    "                                    FROM weather_data as wd\n",
    "                                    JOIN weather_stations as ws ON ws.station_id = wd.station_id\n",
    "                                    WHERE wd.time BETWEEN {min_time} AND {max_time};\n",
    "                                   \"\"\",\n",
    "                                   weather_connection\n",
    "                                    )\n",
    "\n",
    "    # Loads state vectors for the given flight\n",
    "    print('Loading state vectors.')\n",
    "    state_vectors = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT DISTINCT state_vectors.*\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                                   \"\"\",\n",
    "                                   flights_connection)\n",
    "    \n",
    "    # Computes the weather values for the current flight\n",
    "    print('Computing weather values.')\n",
    "    state_vectors = interpolator.compute_flight_weather_quantities(new_columns, state_vectors, stations_data=flight_weather_data)\n",
    "    \n",
    "    # Adds newly calculated values to new table    \n",
    "    print(\"Adding newly calculated values to new table\")\n",
    "    for index, row in state_vectors.iterrows():\n",
    "        # Preparing the data to be inserted\n",
    "        insert_data = tuple(row[col] for col in ['vector_id'] + new_columns)\n",
    "\n",
    "        # Creating query to insert new values\n",
    "        insert_query = f'''\n",
    "            INSERT INTO state_vector_weather (vector_id, {', '.join(new_columns)})\n",
    "            VALUES ({', '.join('?' * len(insert_data))})\n",
    "            ON CONFLICT(vector_id) DO UPDATE SET\n",
    "            {', '.join([f\"{col} = excluded.{col}\" for col in new_columns])};\n",
    "        '''\n",
    "        cursor.execute(insert_query, insert_data)\n",
    "    # Commiting changes to the database\n",
    "    flights_connection.commit()\n",
    "    \n",
    "    with open(tracking_file, 'a') as f:\n",
    "        f.write(flight_id + '\\n')\n",
    "\n",
    "# Closing connections\n",
    "flights_connection.close()\n",
    "weather_connection.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# This variable should indicate the path from this Jupyter Notebook to the root directory of the repo.\n",
    "root_path = '../'\n",
    "# Adds the repo's root to the list of paths\n",
    "sys.path.append(root_path)\n",
    "\n",
    "# Package to read yml files\n",
    "import yaml\n",
    "# Package to handle file paths\n",
    "import os\n",
    "# Package to deal with DataFrames\n",
    "import pandas as pd\n",
    "# Package to plot stuff\n",
    "import matplotlib.pyplot as plt\n",
    "# Package for numerical and array handling\n",
    "import numpy as np\n",
    "# Package to read and write to .sqlite files\n",
    "import sqlite3\n",
    "# Package to keep track of time\n",
    "import datetime\n",
    "\n",
    "# Function to clear output from jupyter notebook\n",
    "from IPython.display import clear_output\n",
    "# Package for compressing dataframes into file\n",
    "from src.data import compressors\n",
    "# Package for defining and fitting weather models\n",
    "from src.models import weather\n",
    "# Utilities package\n",
    "from src.common import utils\n",
    "# Package for interpolating and estimating weather\n",
    "from src.analysis import weather_interpolator\n",
    "\n",
    "# Path from this notebook to the root directory\n",
    "root_path = os.path.normpath(root_path)\n",
    "# Path from root to the desired config file\n",
    "config_path_from_root = os.path.normpath('config/config.yml')\n",
    "# Defining path from this notebook to config file\n",
    "config_path = os.path.join(root_path, config_path_from_root)\n",
    "\n",
    "# Loading config file\n",
    "with open(config_path, 'r',  encoding='utf8') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Defining \"clear-output\" function to feed into logger\n",
    "def clear():\n",
    "    clear_output(wait=True)\n",
    "\n",
    "# Creates an instance of a logger class to log all that happens, optional (but encouraged).\n",
    "logger = utils.Logger(config, clear_function=None)\n",
    "\n",
    "# Creates an instance of the weather interpolator\n",
    "interpolator = weather_interpolator.WeatherInterpolator(config, logger=logger)\n",
    "\n",
    "# Defining location of data\n",
    "flights_database = '../data/flight/KLAX_KSFO_2023-07-01_2023-07-31.sqlite'\n",
    "weather_database = '../data/weather/Weather-US_2023-06-30_2022-08-01.sqlite'\n",
    "\n",
    "# Path to file keeping track of already-loaded flights\n",
    "tracking_file = flights_database.replace('sqlite','txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "database is locked",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# If there is no record of loaded ids, we start from scratch\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(loaded_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Drop the table if it exists\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDROP TABLE IF EXISTS state_vector_weather;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Create the new table\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     create_table_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124m        CREATE TABLE state_vector_weather (\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124m            vector_id INTEGER PRIMARY KEY,\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m REAL\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mcol\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mnew_columns])\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124m        );\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'''\u001b[39m\n",
      "\u001b[0;31mOperationalError\u001b[0m: database is locked"
     ]
    }
   ],
   "source": [
    "# Declares the connections read from each of the databases\n",
    "flights_connection = sqlite3.connect(flights_database)\n",
    "weather_connection = sqlite3.connect(weather_database)\n",
    "# Declares a cursor to write to the database\n",
    "cursor = flights_connection.cursor()\n",
    "\n",
    "# Checking and loading the tracking_file\n",
    "if os.path.isfile(tracking_file):\n",
    "    with open(tracking_file, 'r') as f:\n",
    "        loaded_ids = f.read().split('\\n')\n",
    "        loaded_ids = [i for i in loaded_ids if i != '']\n",
    "else:\n",
    "    with open(tracking_file, 'w') as f:\n",
    "        loaded_ids = []\n",
    "    \n",
    "\n",
    "# Runs a query to identify all the flight_ids available\n",
    "flight_ids = pd.read_sql_query(\"SELECT flight_id FROM flights;\", flights_connection).values[:,0]\n",
    "# Only care about the ids that have not been loaded yet.\n",
    "flight_ids = [f for f in flight_ids if f not in loaded_ids]\n",
    "\n",
    "# Loading the time threshold variable, which is the time interval that weather data will be loaded for each calculation.\n",
    "time_thresh = config['statistics']['interpolation']['weather']['time-thresh']\n",
    "lat_lon_thresh = config['statistics']['interpolation']['weather']['lat-lon-thresh']\n",
    "\n",
    "# The list of columns to be added to the new table to be created.\n",
    "new_columns = ['tmpf', 'air_pressure', 'air_density', 'clouds', 'sknt', 'severity']\n",
    "\n",
    "# If there is no record of loaded ids, we start from scratch\n",
    "if len(loaded_ids) == 0:\n",
    "    # Drop the table if it exists\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS state_vector_weather;\")\n",
    "\n",
    "    # Create the new table\n",
    "    create_table_query = f'''\n",
    "        CREATE TABLE state_vector_weather (\n",
    "            vector_id INTEGER PRIMARY KEY,\n",
    "            {\", \".join([f\"{col} REAL\" for col in new_columns])}\n",
    "        );\n",
    "    '''\n",
    "    # Create the new table if it doesn't exist\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "# Commits change to file\n",
    "flights_connection.commit()\n",
    "\n",
    "t_start_full = datetime.datetime.now()\n",
    "# Looping through flight ids\n",
    "for i, flight_id in enumerate(flight_ids):\n",
    "    time_iteration = datetime.datetime.now()\n",
    "    # Clears output at every loop\n",
    "    clear_output(wait=True)\n",
    "    print(f'{flight_id} | {i}/{len(flight_ids)}.')\n",
    "    time_elapsed = (time_iteration - t_start_full).total_seconds()\n",
    "    if i == 0:\n",
    "        ETA = np.nan\n",
    "    else:\n",
    "        ETA = time_elapsed*len(flight_ids)/i - time_elapsed\n",
    "    print(f'Time Elapsed: {utils.format_time(time_elapsed)}.')\n",
    "    print(f'Estimate time to finish: {utils.format_time(ETA)}.')\n",
    "    \n",
    "    # Finds minimum and maximum flight for current flight\n",
    "    print('Loading time limits.')\n",
    "    min_time, max_time = pd.read_sql_query(f\"\"\"\n",
    "                                SELECT MIN(time) as min_time, MAX(time) as max_time\n",
    "                                FROM state_vectors \n",
    "                                JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                               \"\"\",\n",
    "                              flights_connection\n",
    "                              ).values[0]\n",
    "    \n",
    "    # Finds the minimum and maximum latitudes for the current flight\n",
    "    print('Loading latitude limits.')\n",
    "    min_latitude, max_latitude = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT MIN(lat) as min_lat, MAX(lat) as max_lat\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\"\n",
    "                                   \"\"\",\n",
    "                                  flights_connection\n",
    "                                  ).values[0]\n",
    "\n",
    "    print('Loading longitude limits.')\n",
    "    # Finds the minimum and maximum longitudes for the current flight\n",
    "    min_longitude, max_longitude = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT MIN(lon) as min_lon, MAX(lon) as max_lon\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\"\n",
    "                                   \"\"\",\n",
    "                                  flights_connection\n",
    "                                  ).values[0]\n",
    "    \n",
    "    # Adjusting time, lat and lon thresholds.\n",
    "    print(\"Adjusting time, lat, lon thresholds.\")\n",
    "    # Adds time threshold to time limits\n",
    "    min_time -= time_thresh\n",
    "    max_time += time_thresh\n",
    "    \n",
    "    # Adds latitude and longitude threshold\n",
    "    range_latitude = max_latitude - min_latitude\n",
    "    range_longitude = max_longitude - min_longitude\n",
    "    min_latitude -= range_latitude*lat_lon_thresh\n",
    "    max_latitude += range_latitude*lat_lon_thresh\n",
    "    min_longitude -= range_longitude*lat_lon_thresh\n",
    "    max_longitude += range_longitude*lat_lon_thresh    \n",
    "    \n",
    "    # Loads the weather data corresponding to the flight\n",
    "    print('Loading relevant weather data.')\n",
    "    flight_weather_data = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT ws.lat, ws.lon, ws.elevation, ws.sigma, wd.*\n",
    "                                    FROM weather_data as wd\n",
    "                                    JOIN weather_stations as ws ON ws.station_id = wd.station_id\n",
    "                                    WHERE wd.time BETWEEN {min_time} AND {max_time};\n",
    "                                   \"\"\",\n",
    "                                   weather_connection\n",
    "                                    )\n",
    "\n",
    "    # Loads state vectors for the given flight\n",
    "    print('Loading state vectors.')\n",
    "    state_vectors = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT DISTINCT state_vectors.*\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                                   \"\"\",\n",
    "                                   flights_connection)\n",
    "    \n",
    "    # Computes the weather values for the current flight\n",
    "    print('Computing weather values.')\n",
    "    state_vectors = interpolator.compute_flight_weather_quantities(new_columns, state_vectors, stations_data=flight_weather_data)\n",
    "    \n",
    "    # Adds newly calculated values to new table    \n",
    "    print(\"Adding newly calculated values to new table\")\n",
    "    for index, row in state_vectors.iterrows():\n",
    "        # Preparing the data to be inserted\n",
    "        insert_data = tuple(row[col] for col in ['vector_id'] + new_columns)\n",
    "\n",
    "        # Creating query to insert new values\n",
    "        insert_query = f'''\n",
    "            INSERT INTO state_vector_weather (vector_id, {', '.join(new_columns)})\n",
    "            VALUES ({', '.join('?' * len(insert_data))})\n",
    "            ON CONFLICT(vector_id) DO UPDATE SET\n",
    "            {', '.join([f\"{col} = excluded.{col}\" for col in new_columns])};\n",
    "        '''\n",
    "        cursor.execute(insert_query, insert_data)\n",
    "    # Commiting changes to the database\n",
    "    flights_connection.commit()\n",
    "    \n",
    "    with open(tracking_file, 'a') as f:\n",
    "        f.write(flight_id + '\\n')\n",
    "\n",
    "# Closing connections\n",
    "flights_connection.close()\n",
    "weather_connection.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# This variable should indicate the path from this Jupyter Notebook to the root directory of the repo.\n",
    "root_path = '../'\n",
    "# Adds the repo's root to the list of paths\n",
    "sys.path.append(root_path)\n",
    "\n",
    "# Package to read yml files\n",
    "import yaml\n",
    "# Package to handle file paths\n",
    "import os\n",
    "# Package to deal with DataFrames\n",
    "import pandas as pd\n",
    "# Package to plot stuff\n",
    "import matplotlib.pyplot as plt\n",
    "# Package for numerical and array handling\n",
    "import numpy as np\n",
    "# Package to read and write to .sqlite files\n",
    "import sqlite3\n",
    "# Package to keep track of time\n",
    "import datetime\n",
    "\n",
    "# Function to clear output from jupyter notebook\n",
    "from IPython.display import clear_output\n",
    "# Package for compressing dataframes into file\n",
    "from src.data import compressors\n",
    "# Package for defining and fitting weather models\n",
    "from src.models import weather\n",
    "# Utilities package\n",
    "from src.common import utils\n",
    "# Package for interpolating and estimating weather\n",
    "from src.analysis import weather_interpolator\n",
    "\n",
    "# Path from this notebook to the root directory\n",
    "root_path = os.path.normpath(root_path)\n",
    "# Path from root to the desired config file\n",
    "config_path_from_root = os.path.normpath('config/config.yml')\n",
    "# Defining path from this notebook to config file\n",
    "config_path = os.path.join(root_path, config_path_from_root)\n",
    "\n",
    "# Loading config file\n",
    "with open(config_path, 'r',  encoding='utf8') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Defining \"clear-output\" function to feed into logger\n",
    "def clear():\n",
    "    clear_output(wait=True)\n",
    "\n",
    "# Creates an instance of a logger class to log all that happens, optional (but encouraged).\n",
    "logger = utils.Logger(config, clear_function=None)\n",
    "\n",
    "# Creates an instance of the weather interpolator\n",
    "interpolator = weather_interpolator.WeatherInterpolator(config, logger=logger)\n",
    "\n",
    "# Defining location of data\n",
    "flights_database = '../data/flight/KSEA_KDEN_2023-07-01_2023-07-31.sqlite'\n",
    "weather_database = '../data/weather/Weather-US_2023-06-30_2022-08-01.sqlite'\n",
    "\n",
    "# Path to file keeping track of already-loaded flights\n",
    "tracking_file = flights_database.replace('sqlite','txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declares the connections read from each of the databases\n",
    "flights_connection = sqlite3.connect(flights_database)\n",
    "weather_connection = sqlite3.connect(weather_database)\n",
    "# Declares a cursor to write to the database\n",
    "cursor = flights_connection.cursor()\n",
    "\n",
    "# Checking and loading the tracking_file\n",
    "if os.path.isfile(tracking_file):\n",
    "    with open(tracking_file, 'r') as f:\n",
    "        loaded_ids = f.read().split('\\n')\n",
    "        loaded_ids = [i for i in loaded_ids if i != '']\n",
    "else:\n",
    "    with open(tracking_file, 'w') as f:\n",
    "        loaded_ids = []\n",
    "    \n",
    "\n",
    "# Runs a query to identify all the flight_ids available\n",
    "flight_ids = pd.read_sql_query(\"SELECT flight_id FROM flights;\", flights_connection).values[:,0]\n",
    "# Only care about the ids that have not been loaded yet.\n",
    "flight_ids = [f for f in flight_ids if f not in loaded_ids]\n",
    "\n",
    "# Loading the time threshold variable, which is the time interval that weather data will be loaded for each calculation.\n",
    "time_thresh = config['statistics']['interpolation']['weather']['time-thresh']\n",
    "lat_lon_thresh = config['statistics']['interpolation']['weather']['lat-lon-thresh']\n",
    "\n",
    "# The list of columns to be added to the new table to be created.\n",
    "new_columns = ['tmpf', 'air_pressure', 'air_density', 'clouds', 'sknt', 'severity']\n",
    "\n",
    "# If there is no record of loaded ids, we start from scratch\n",
    "if len(loaded_ids) == 0:\n",
    "    # Drop the table if it exists\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS state_vector_weather;\")\n",
    "\n",
    "    # Create the new table\n",
    "    create_table_query = f'''\n",
    "        CREATE TABLE state_vector_weather (\n",
    "            vector_id INTEGER PRIMARY KEY,\n",
    "            {\", \".join([f\"{col} REAL\" for col in new_columns])}\n",
    "        );\n",
    "    '''\n",
    "    # Create the new table if it doesn't exist\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "# Commits change to file\n",
    "flights_connection.commit()\n",
    "\n",
    "t_start_full = datetime.datetime.now()\n",
    "# Looping through flight ids\n",
    "for i, flight_id in enumerate(flight_ids):\n",
    "    time_iteration = datetime.datetime.now()\n",
    "    # Clears output at every loop\n",
    "    clear_output(wait=True)\n",
    "    print(f'{flight_id} | {i}/{len(flight_ids)}.')\n",
    "    time_elapsed = (time_iteration - t_start_full).total_seconds()\n",
    "    if i == 0:\n",
    "        ETA = np.nan\n",
    "    else:\n",
    "        ETA = time_elapsed*len(flight_ids)/i - time_elapsed\n",
    "    print(f'Time Elapsed: {utils.format_time(time_elapsed)}.')\n",
    "    print(f'Estimate time to finish: {utils.format_time(ETA)}.')\n",
    "    \n",
    "    # Finds minimum and maximum flight for current flight\n",
    "    print('Loading time limits.')\n",
    "    min_time, max_time = pd.read_sql_query(f\"\"\"\n",
    "                                SELECT MIN(time) as min_time, MAX(time) as max_time\n",
    "                                FROM state_vectors \n",
    "                                JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                               \"\"\",\n",
    "                              flights_connection\n",
    "                              ).values[0]\n",
    "    \n",
    "    # Finds the minimum and maximum latitudes for the current flight\n",
    "    print('Loading latitude limits.')\n",
    "    min_latitude, max_latitude = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT MIN(lat) as min_lat, MAX(lat) as max_lat\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\"\n",
    "                                   \"\"\",\n",
    "                                  flights_connection\n",
    "                                  ).values[0]\n",
    "\n",
    "    print('Loading longitude limits.')\n",
    "    # Finds the minimum and maximum longitudes for the current flight\n",
    "    min_longitude, max_longitude = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT MIN(lon) as min_lon, MAX(lon) as max_lon\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\"\n",
    "                                   \"\"\",\n",
    "                                  flights_connection\n",
    "                                  ).values[0]\n",
    "    \n",
    "    # Adjusting time, lat and lon thresholds.\n",
    "    print(\"Adjusting time, lat, lon thresholds.\")\n",
    "    # Adds time threshold to time limits\n",
    "    min_time -= time_thresh\n",
    "    max_time += time_thresh\n",
    "    \n",
    "    # Adds latitude and longitude threshold\n",
    "    range_latitude = max_latitude - min_latitude\n",
    "    range_longitude = max_longitude - min_longitude\n",
    "    min_latitude -= range_latitude*lat_lon_thresh\n",
    "    max_latitude += range_latitude*lat_lon_thresh\n",
    "    min_longitude -= range_longitude*lat_lon_thresh\n",
    "    max_longitude += range_longitude*lat_lon_thresh    \n",
    "    \n",
    "    # Loads the weather data corresponding to the flight\n",
    "    print('Loading relevant weather data.')\n",
    "    flight_weather_data = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT ws.lat, ws.lon, ws.elevation, ws.sigma, wd.*\n",
    "                                    FROM weather_data as wd\n",
    "                                    JOIN weather_stations as ws ON ws.station_id = wd.station_id\n",
    "                                    WHERE wd.time BETWEEN {min_time} AND {max_time};\n",
    "                                   \"\"\",\n",
    "                                   weather_connection\n",
    "                                    )\n",
    "\n",
    "    # Loads state vectors for the given flight\n",
    "    print('Loading state vectors.')\n",
    "    state_vectors = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT DISTINCT state_vectors.*\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                                   \"\"\",\n",
    "                                   flights_connection)\n",
    "    \n",
    "    # Computes the weather values for the current flight\n",
    "    print('Computing weather values.')\n",
    "    state_vectors = interpolator.compute_flight_weather_quantities(new_columns, state_vectors, stations_data=flight_weather_data)\n",
    "    \n",
    "    # Adds newly calculated values to new table    \n",
    "    print(\"Adding newly calculated values to new table\")\n",
    "    for index, row in state_vectors.iterrows():\n",
    "        # Preparing the data to be inserted\n",
    "        insert_data = tuple(row[col] for col in ['vector_id'] + new_columns)\n",
    "\n",
    "        # Creating query to insert new values\n",
    "        insert_query = f'''\n",
    "            INSERT INTO state_vector_weather (vector_id, {', '.join(new_columns)})\n",
    "            VALUES ({', '.join('?' * len(insert_data))})\n",
    "            ON CONFLICT(vector_id) DO UPDATE SET\n",
    "            {', '.join([f\"{col} = excluded.{col}\" for col in new_columns])};\n",
    "        '''\n",
    "        cursor.execute(insert_query, insert_data)\n",
    "    # Commiting changes to the database\n",
    "    flights_connection.commit()\n",
    "    \n",
    "    with open(tracking_file, 'a') as f:\n",
    "        f.write(flight_id + '\\n')\n",
    "\n",
    "# Closing connections\n",
    "flights_connection.close()\n",
    "weather_connection.closeose()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# This variable should indicate the path from this Jupyter Notebook to the root directory of the repo.\n",
    "root_path = '../'\n",
    "# Adds the repo's root to the list of paths\n",
    "sys.path.append(root_path)\n",
    "\n",
    "# Package to read yml files\n",
    "import yaml\n",
    "# Package to handle file paths\n",
    "import os\n",
    "# Package to deal with DataFrames\n",
    "import pandas as pd\n",
    "# Package to plot stuff\n",
    "import matplotlib.pyplot as plt\n",
    "# Package for numerical and array handling\n",
    "import numpy as np\n",
    "# Package to read and write to .sqlite files\n",
    "import sqlite3\n",
    "# Package to keep track of time\n",
    "import datetime\n",
    "\n",
    "# Function to clear output from jupyter notebook\n",
    "from IPython.display import clear_output\n",
    "# Package for compressing dataframes into file\n",
    "from src.data import compressors\n",
    "# Package for defining and fitting weather models\n",
    "from src.models import weather\n",
    "# Utilities package\n",
    "from src.common import utils\n",
    "# Package for interpolating and estimating weather\n",
    "from src.analysis import weather_interpolator\n",
    "\n",
    "# Path from this notebook to the root directory\n",
    "root_path = os.path.normpath(root_path)\n",
    "# Path from root to the desired config file\n",
    "config_path_from_root = os.path.normpath('config/config.yml')\n",
    "# Defining path from this notebook to config file\n",
    "config_path = os.path.join(root_path, config_path_from_root)\n",
    "\n",
    "# Loading config file\n",
    "with open(config_path, 'r',  encoding='utf8') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Defining \"clear-output\" function to feed into logger\n",
    "def clear():\n",
    "    clear_output(wait=True)\n",
    "\n",
    "# Creates an instance of a logger class to log all that happens, optional (but encouraged).\n",
    "logger = utils.Logger(config, clear_function=None)\n",
    "\n",
    "# Creates an instance of the weather interpolator\n",
    "interpolator = weather_interpolator.WeatherInterpolator(config, logger=logger)\n",
    "\n",
    "# Defining location of data\n",
    "flights_database = '../data/flight/KSFO_KLAX_2023-07-01_2023-07-31.sqlite'\n",
    "weather_database = '../data/weather/Weather-US_2023-06-30_2022-08-01.sqlite'\n",
    "\n",
    "# Path to file keeping track of already-loaded flights\n",
    "tracking_file = flights_database.replace('sqlite','txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declares the connections read from each of the databases\n",
    "flights_connection = sqlite3.connect(flights_database)\n",
    "weather_connection = sqlite3.connect(weather_database)\n",
    "# Declares a cursor to write to the database\n",
    "cursor = flights_connection.cursor()\n",
    "\n",
    "# Checking and loading the tracking_file\n",
    "if os.path.isfile(tracking_file):\n",
    "    with open(tracking_file, 'r') as f:\n",
    "        loaded_ids = f.read().split('\\n')\n",
    "        loaded_ids = [i for i in loaded_ids if i != '']\n",
    "else:\n",
    "    with open(tracking_file, 'w') as f:\n",
    "        loaded_ids = []\n",
    "    \n",
    "\n",
    "# Runs a query to identify all the flight_ids available\n",
    "flight_ids = pd.read_sql_query(\"SELECT flight_id FROM flights;\", flights_connection).values[:,0]\n",
    "# Only care about the ids that have not been loaded yet.\n",
    "flight_ids = [f for f in flight_ids if f not in loaded_ids]\n",
    "\n",
    "# Loading the time threshold variable, which is the time interval that weather data will be loaded for each calculation.\n",
    "time_thresh = config['statistics']['interpolation']['weather']['time-thresh']\n",
    "lat_lon_thresh = config['statistics']['interpolation']['weather']['lat-lon-thresh']\n",
    "\n",
    "# The list of columns to be added to the new table to be created.\n",
    "new_columns = ['tmpf', 'air_pressure', 'air_density', 'clouds', 'sknt', 'severity']\n",
    "\n",
    "# If there is no record of loaded ids, we start from scratch\n",
    "if len(loaded_ids) == 0:\n",
    "    # Drop the table if it exists\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS state_vector_weather;\")\n",
    "\n",
    "    # Create the new table\n",
    "    create_table_query = f'''\n",
    "        CREATE TABLE state_vector_weather (\n",
    "            vector_id INTEGER PRIMARY KEY,\n",
    "            {\", \".join([f\"{col} REAL\" for col in new_columns])}\n",
    "        );\n",
    "    '''\n",
    "    # Create the new table if it doesn't exist\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "# Commits change to file\n",
    "flights_connection.commit()\n",
    "\n",
    "t_start_full = datetime.datetime.now()\n",
    "# Looping through flight ids\n",
    "for i, flight_id in enumerate(flight_ids):\n",
    "    time_iteration = datetime.datetime.now()\n",
    "    # Clears output at every loop\n",
    "    clear_output(wait=True)\n",
    "    print(f'{flight_id} | {i}/{len(flight_ids)}.')\n",
    "    time_elapsed = (time_iteration - t_start_full).total_seconds()\n",
    "    if i == 0:\n",
    "        ETA = np.nan\n",
    "    else:\n",
    "        ETA = time_elapsed*len(flight_ids)/i - time_elapsed\n",
    "    print(f'Time Elapsed: {utils.format_time(time_elapsed)}.')\n",
    "    print(f'Estimate time to finish: {utils.format_time(ETA)}.')\n",
    "    \n",
    "    # Finds minimum and maximum flight for current flight\n",
    "    print('Loading time limits.')\n",
    "    min_time, max_time = pd.read_sql_query(f\"\"\"\n",
    "                                SELECT MIN(time) as min_time, MAX(time) as max_time\n",
    "                                FROM state_vectors \n",
    "                                JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                               \"\"\",\n",
    "                              flights_connection\n",
    "                              ).values[0]\n",
    "    \n",
    "    # Finds the minimum and maximum latitudes for the current flight\n",
    "    print('Loading latitude limits.')\n",
    "    min_latitude, max_latitude = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT MIN(lat) as min_lat, MAX(lat) as max_lat\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\"\n",
    "                                   \"\"\",\n",
    "                                  flights_connection\n",
    "                                  ).values[0]\n",
    "\n",
    "    print('Loading longitude limits.')\n",
    "    # Finds the minimum and maximum longitudes for the current flight\n",
    "    min_longitude, max_longitude = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT MIN(lon) as min_lon, MAX(lon) as max_lon\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\"\n",
    "                                   \"\"\",\n",
    "                                  flights_connection\n",
    "                                  ).values[0]\n",
    "    \n",
    "    # Adjusting time, lat and lon thresholds.\n",
    "    print(\"Adjusting time, lat, lon thresholds.\")\n",
    "    # Adds time threshold to time limits\n",
    "    min_time -= time_thresh\n",
    "    max_time += time_thresh\n",
    "    \n",
    "    # Adds latitude and longitude threshold\n",
    "    range_latitude = max_latitude - min_latitude\n",
    "    range_longitude = max_longitude - min_longitude\n",
    "    min_latitude -= range_latitude*lat_lon_thresh\n",
    "    max_latitude += range_latitude*lat_lon_thresh\n",
    "    min_longitude -= range_longitude*lat_lon_thresh\n",
    "    max_longitude += range_longitude*lat_lon_thresh    \n",
    "    \n",
    "    # Loads the weather data corresponding to the flight\n",
    "    print('Loading relevant weather data.')\n",
    "    flight_weather_data = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT ws.lat, ws.lon, ws.elevation, ws.sigma, wd.*\n",
    "                                    FROM weather_data as wd\n",
    "                                    JOIN weather_stations as ws ON ws.station_id = wd.station_id\n",
    "                                    WHERE wd.time BETWEEN {min_time} AND {max_time};\n",
    "                                   \"\"\",\n",
    "                                   weather_connection\n",
    "                                    )\n",
    "\n",
    "    # Loads state vectors for the given flight\n",
    "    print('Loading state vectors.')\n",
    "    state_vectors = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT DISTINCT state_vectors.*\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                                   \"\"\",\n",
    "                                   flights_connection)\n",
    "    \n",
    "    # Computes the weather values for the current flight\n",
    "    print('Computing weather values.')\n",
    "    state_vectors = interpolator.compute_flight_weather_quantities(new_columns, state_vectors, stations_data=flight_weather_data)\n",
    "    \n",
    "    # Adds newly calculated values to new table    \n",
    "    print(\"Adding newly calculated values to new table\")\n",
    "    for index, row in state_vectors.iterrows():\n",
    "        # Preparing the data to be inserted\n",
    "        insert_data = tuple(row[col] for col in ['vector_id'] + new_columns)\n",
    "\n",
    "        # Creating query to insert new values\n",
    "        insert_query = f'''\n",
    "            INSERT INTO state_vector_weather (vector_id, {', '.join(new_columns)})\n",
    "            VALUES ({', '.join('?' * len(insert_data))})\n",
    "            ON CONFLICT(vector_id) DO UPDATE SET\n",
    "            {', '.join([f\"{col} = excluded.{col}\" for col in new_columns])};\n",
    "        '''\n",
    "        cursor.execute(insert_query, insert_data)\n",
    "    # Commiting changes to the database\n",
    "    flights_connection.commit()\n",
    "    \n",
    "    with open(tracking_file, 'a') as f:\n",
    "        f.write(flight_id + '\\n')\n",
    "\n",
    "# Closing connections\n",
    "flights_connection.close()\n",
    "weather_connection.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FlightStats",
   "language": "python",
   "name": "flightstats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
