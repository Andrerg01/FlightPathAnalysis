{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Weather for Each Flight Route\n",
    "\n",
    "This notebook should have everything you need to compute the weather conditions selected for a given flight.\n",
    "\n",
    "To make this work, make sure you have the following done:\n",
    " - Rename the `config/config_template.yml` file as `config/config.yml`\n",
    " - Change the `base-configs - root-directory` entry to wherever you downloaded the project repo\n",
    " - Change the `base-configs - tag` entry to whatever you'd like to, I don't think it'll matter, but who knows\n",
    " - Make sure all the dependencies are installed with `pip install -r requirements.txt`\n",
    " - Change the `flights_database` and `weather_database` variables below to whatever flight one you assigned yourself to, and the corresponding weather\n",
    " - Have fun and pray for no bugs!\n",
    " - If you need to make an environment readable on Jupyter you can follow [this guide](https://medium.com/@nrk25693/how-to-add-your-conda-environment-to-your-jupyter-notebook-in-just-4-steps-abeab8b8d084). If not, just copy the code and make it into a script. Up to ya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# This variable should indicate the path from this Jupyter Notebook to the root directory of the repo.\n",
    "root_path = '../'\n",
    "# Adds the repo's root to the list of paths\n",
    "sys.path.append(root_path)\n",
    "\n",
    "# Package to read yml files\n",
    "import yaml\n",
    "# Package to handle file paths\n",
    "import os\n",
    "# Package to deal with DataFrames\n",
    "import pandas as pd\n",
    "# Package to plot stuff\n",
    "import matplotlib.pyplot as plt\n",
    "# Package for numerical and array handling\n",
    "import numpy as np\n",
    "# Package to read and write to .sqlite files\n",
    "import sqlite3\n",
    "# Package to keep track of time\n",
    "import datetime\n",
    "\n",
    "# Function to clear output from jupyter notebook\n",
    "from IPython.display import clear_output\n",
    "# Package for compressing dataframes into file\n",
    "from src.data import compressors\n",
    "# Package for defining and fitting weather models\n",
    "from src.models import weather\n",
    "# Utilities package\n",
    "from src.common import utils\n",
    "# Package for interpolating and estimating weather\n",
    "from src.analysis import weather_interpolator\n",
    "\n",
    "# Path from this notebook to the root directory\n",
    "root_path = os.path.normpath(root_path)\n",
    "# Path from root to the desired config file\n",
    "config_path_from_root = os.path.normpath('config/config.yml')\n",
    "# Defining path from this notebook to config file\n",
    "config_path = os.path.join(root_path, config_path_from_root)\n",
    "\n",
    "# Loading config file\n",
    "with open(config_path, 'r',  encoding='utf8') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Defining \"clear-output\" function to feed into logger\n",
    "def clear():\n",
    "    clear_output(wait=True)\n",
    "\n",
    "# Creates an instance of a logger class to log all that happens, optional (but encouraged).\n",
    "logger = utils.Logger(config, clear_function=None)\n",
    "\n",
    "# Creates an instance of the weather interpolator\n",
    "interpolator = weather_interpolator.WeatherInterpolator(config, logger=logger)\n",
    "\n",
    "# Defining location of data\n",
    "flights_database = '../data/flight/KDEN_KSEA_2023-01-01_2023-01-31.sqlite'\n",
    "weather_database = '../data/weather/1673827200_1685923200.sqlite'\n",
    "\n",
    "# Path to file keeping track of already-loaded flights\n",
    "tracking_file = 'weather_flights_loaded.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada167_1672524657_1672534041_KDEN_KSEA | 0/649.\n",
      "Time Elapsed: 0s.\n",
      "Estimate time to finish: NaN.\n",
      "Loading time limits.\n",
      "Loading latitude limits.\n",
      "Adjusting time, lat, lon thresholds.\n",
      "Loading relevant weather data.\n"
     ]
    }
   ],
   "source": [
    "# Declares the connections read from each of the databases\n",
    "flights_connection = sqlite3.connect(flights_database)\n",
    "weather_connection = sqlite3.connect(weather_database)\n",
    "# Declares a cursor to write to the database\n",
    "cursor = flights_connection.cursor()\n",
    "\n",
    "# Checking and loading the tracking_file\n",
    "if os.path.isfile(tracking_file):\n",
    "    with open(tracking_file, 'r') as f:\n",
    "        loaded_ids = f.read().split('\\n')\n",
    "        loaded_ids = [i for i in loaded_ids if i != '']\n",
    "else:\n",
    "    with open(tracking_file, 'w') as f:\n",
    "        loaded_ids = []\n",
    "    \n",
    "\n",
    "# Runs a query to identify all the flight_ids available\n",
    "flight_ids = pd.read_sql_query(\"SELECT flight_id FROM flights;\", flights_connection).values[:,0]\n",
    "# Only care about the ids that have not been loaded yet.\n",
    "flight_ids = [f for f in flight_ids if f not in loaded_ids]\n",
    "\n",
    "# Loading the time threshold variable, which is the time interval that weather data will be loaded for each calculation.\n",
    "time_thresh = config['statistics']['interpolation']['weather']['time-thresh']\n",
    "lat_lon_thresh = config['statistics']['interpolation']['weather']['lat-lon-thresh']\n",
    "\n",
    "# The list of columns to be added to the new table to be created.\n",
    "new_columns = ['tmpf', 'air_pressure', 'air_density', 'clouds', 'sknt', 'severity']\n",
    "\n",
    "# If there is no record of loaded ids, we start from scratch\n",
    "if len(loaded_ids) == 0:\n",
    "    # Drop the table if it exists\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS state_vector_weather;\")\n",
    "\n",
    "    # Create the new table\n",
    "    create_table_query = f'''\n",
    "        CREATE TABLE state_vector_weather (\n",
    "            vector_id INTEGER PRIMARY KEY,\n",
    "            {\", \".join([f\"{col} REAL\" for col in new_columns])}\n",
    "        );\n",
    "    '''\n",
    "    # Create the new table if it doesn't exist\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "# Commits change to file\n",
    "flights_connection.commit()\n",
    "\n",
    "t_start_full = datetime.datetime.now()\n",
    "# Looping through flight ids\n",
    "for i, flight_id in enumerate(flight_ids):\n",
    "    time_iteration = datetime.datetime.now()\n",
    "    # Clears output at every loop\n",
    "    clear_output(wait=True)\n",
    "    print(f'{flight_id} | {i}/{len(flight_ids)}.')\n",
    "    time_elapsed = (time_iteration - t_start_full).total_seconds()\n",
    "    if i == 0:\n",
    "        ETA = np.nan\n",
    "    else:\n",
    "        ETA = time_elapsed*len(flight_ids)/i - time_elapsed\n",
    "    print(f'Time Elapsed: {utils.format_time(time_elapsed)}.')\n",
    "    print(f'Estimate time to finish: {utils.format_time(ETA)}.')\n",
    "    \n",
    "    # Finds minimum and maximum flight for current flight\n",
    "    print('Loading time limits.')\n",
    "    min_time, max_time = pd.read_sql_query(f\"\"\"\n",
    "                                SELECT MIN(time) as min_time, MAX(time) as max_time\n",
    "                                FROM state_vectors \n",
    "                                JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                               \"\"\",\n",
    "                              flights_connection\n",
    "                              ).values[0]\n",
    "    \n",
    "    # Finds the minimum and maximum latitudes for the current flight\n",
    "    print('Loading latitude limits.')\n",
    "    min_latitude, max_latitude = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT MIN(lat) as min_lat, MAX(lat) as max_lat\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\"\n",
    "                                   \"\"\",\n",
    "                                  flights_connection\n",
    "                                  ).values[0]\n",
    "\n",
    "    # Finds the minimum and maximum longitudes for the current flight\n",
    "    min_longitude, max_longitude = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT MIN(lon) as min_lon, MAX(lon) as max_lon\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\"\n",
    "                                   \"\"\",\n",
    "                                  flights_connection\n",
    "                                  ).values[0]\n",
    "    \n",
    "    # Adjusting time, lat and lon thresholds.\n",
    "    print(\"Adjusting time, lat, lon thresholds.\")\n",
    "    # Adds time threshold to time limits\n",
    "    min_time -= time_thresh\n",
    "    max_time += time_thresh\n",
    "    \n",
    "    # Adds latitude and longitude threshold\n",
    "    range_latitude = max_latitude - min_latitude\n",
    "    range_longitude = max_longitude - min_longitude\n",
    "    min_latitude -= range_latitude*lat_lon_thresh\n",
    "    max_latitude += range_latitude*lat_lon_thresh\n",
    "    min_longitude -= range_longitude*lat_lon_thresh\n",
    "    max_longitude += range_longitude*lat_lon_thresh    \n",
    "    \n",
    "    # Loads the weather data corresponding to the flight\n",
    "    print('Loading relevant weather data.')\n",
    "    flight_weather_data = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT ws.lat, ws.lon, ws.elevation, ws.sigma, wd.*\n",
    "                                    FROM weather_data as wd\n",
    "                                    JOIN weather_stations as ws ON ws.station_id = wd.station_id\n",
    "                                    WHERE wd.time BETWEEN {min_time} AND {max_time};\n",
    "                                   \"\"\",\n",
    "                                   weather_connection\n",
    "                                    )\n",
    "\n",
    "    # Loads state vectors for the given flight\n",
    "    print('Loading state vectors.')\n",
    "    state_vectors = pd.read_sql_query(f\"\"\"\n",
    "                                    SELECT DISTINCT state_vectors.*\n",
    "                                    FROM state_vectors \n",
    "                                    JOIN flights ON flights.flight_id = state_vectors.flight_id\n",
    "                                    WHERE state_vectors.flight_id = \"{flight_id}\";\n",
    "                                   \"\"\",\n",
    "                                   flights_connection)\n",
    "    \n",
    "    # Computes the weather values for the current flight\n",
    "    print('Computing weather values.')\n",
    "    state_vectors = interpolator.compute_flight_weather_quantities(new_columns, state_vectors, stations_data=flight_weather_data)\n",
    "    \n",
    "    # Adds newly calculated values to new table    \n",
    "    print(\"Adding newly calculated values to new table\")\n",
    "    for index, row in state_vectors.iterrows():\n",
    "        # Preparing the data to be inserted\n",
    "        insert_data = tuple(row[col] for col in ['vector_id'] + new_columns)\n",
    "\n",
    "        # Creating query to insert new values\n",
    "        insert_query = f'''\n",
    "            INSERT INTO state_vector_weather (vector_id, {', '.join(new_columns)})\n",
    "            VALUES ({', '.join('?' * len(insert_data))})\n",
    "            ON CONFLICT(vector_id) DO UPDATE SET\n",
    "            {', '.join([f\"{col} = excluded.{col}\" for col in new_columns])};\n",
    "        '''\n",
    "        cursor.execute(insert_query, insert_data)\n",
    "    # Commiting changes to the database\n",
    "    flights_connection.commit()\n",
    "    \n",
    "    with open(tracking_file, 'a') as f:\n",
    "        f.write(flight_id + '\\n')\n",
    "\n",
    "# Closing connections\n",
    "flights_connection.close()\n",
    "weather_connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FlightStats",
   "language": "python",
   "name": "flightstats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
