{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# This variable should indicate the path from this Jupyter Notebook to the root directory of the repo.\n",
    "root_path = '../'\n",
    "# Adds the repo's root to the list of paths\n",
    "sys.path.append(root_path)\n",
    "\n",
    "# Package to read yml files\n",
    "import yaml\n",
    "# Package to handle file paths\n",
    "import os\n",
    "# Package to deal with DataFrames\n",
    "import pandas as pd\n",
    "# Package to edit sqlite file\n",
    "import sqlite3\n",
    "# Function to clear output\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Package for compressing dataframes into file\n",
    "from src.data import compressors\n",
    "# Package for defining and fitting weather models\n",
    "from src.models import weather\n",
    "# Utilities package\n",
    "from src.common import utils\n",
    "# Package for interpolating and estimating weather\n",
    "from src.analysis import weather_interpolator\n",
    "\n",
    "# Path from this notebook to the root directory\n",
    "root_path = os.path.normpath(root_path)\n",
    "# Path from root to the desired config file\n",
    "config_path_from_root = os.path.normpath('config/config_tutorial.yml') \n",
    "# Defining path from this notebook to config file\n",
    "config_path = os.path.join(root_path, config_path_from_root) \n",
    "\n",
    "# Loading config file\n",
    "with open(config_path, 'r',  encoding='utf8') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Defining \"clear-output\" function to feed into logger\n",
    "def clear():\n",
    "    clear_output(wait=True)\n",
    "\n",
    "# Creates an instance of a logger class to log all that happens, optional (but encouraged).\n",
    "logger = utils.Logger(config, clear_function=None)\n",
    "\n",
    "# Creates an isntance of the CsvCompressor\n",
    "compressor = compressors.CsvCompressor(config, logger=logger)\n",
    "\n",
    "# Creates an instance of the weather interpolator\n",
    "interpolator = weather_interpolator.WeatherInterpolator(config, logger=logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flights_table(conn):\n",
    "    create_table_sql = '''\n",
    "    CREATE TABLE IF NOT EXISTS flights (\n",
    "        flight_id TEXT PRIMARY KEY,\n",
    "        icao24 TEXT,\n",
    "        callsign TEXT,\n",
    "        departure_airport TEXT,\n",
    "        arrival_airport TEXT\n",
    "    );\n",
    "    '''\n",
    "    conn.execute(create_table_sql)\n",
    "\n",
    "def create_state_vectors_table(conn):\n",
    "    create_table_sql = '''\n",
    "    CREATE TABLE IF NOT EXISTS state_vectors (\n",
    "        vector_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        flight_id TEXT,\n",
    "        time INT,\n",
    "        time_normalized INT,\n",
    "        lat REAL,\n",
    "        lon REAL,\n",
    "        geoaltitude REAL,\n",
    "        baroaltitude REAL,\n",
    "        heading REAL,\n",
    "        velocity REAL,\n",
    "        FOREIGN KEY (flight_id) REFERENCES flights(flight_id)\n",
    "    );\n",
    "    '''\n",
    "    conn.execute(create_table_sql)\n",
    "\n",
    "def create_station_data_table(conn):\n",
    "    create_table_sql = '''\n",
    "    CREATE TABLE IF NOT EXISTS weather_stations (\n",
    "        station_id TEXT PRIMARY KEY,\n",
    "        lon REAL,\n",
    "        lat REAL,\n",
    "        elevation REAL,\n",
    "        sname TEXT,\n",
    "        time_domain TEXT,\n",
    "        archive_begin TEXT,\n",
    "        archive_end TEXT,\n",
    "        state TEXT,\n",
    "        country TEXT,\n",
    "        climate_site TEXT,\n",
    "        wfo TEXT,\n",
    "        tzname TEXT,\n",
    "        ncdc81 TEXT,\n",
    "        ncei91 TEXT,\n",
    "        ugc_county TEXT,\n",
    "        ugc_zone TEXT,\n",
    "        county TEXT,\n",
    "        network TEXT,\n",
    "        online BOOL,\n",
    "        sigma REAL\n",
    "    );\n",
    "    '''\n",
    "    conn.execute(create_table_sql)\n",
    "        \n",
    "def create_weather_data_table(conn):\n",
    "    create_table_sql = '''\n",
    "    CREATE TABLE IF NOT EXISTS weather_data (\n",
    "        weather_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        station_id TEXT,\n",
    "        time INT,\n",
    "        tmpf REAL,\n",
    "        relh REAL,\n",
    "        drct INT,\n",
    "        sknt REAL,\n",
    "        sknt_E REAL,\n",
    "        sknt_N REAL,\n",
    "        p01i REAL,\n",
    "        skyc1 TEXT,\n",
    "        skyc2 TEXT,\n",
    "        skyc3 TEXT,\n",
    "        skyc4 TEXT,\n",
    "        skyl1 INT,\n",
    "        skyl2 INT,\n",
    "        skyl3 INT,\n",
    "        skyl4 INT,\n",
    "        wxcodes TEXT,\n",
    "        wx REAL,\n",
    "        ice_accretion_1hr REAL,\n",
    "        METAR TEXT,\n",
    "        FOREIGN KEY (station_id) REFERENCES weather_sations(station_id)\n",
    "    );\n",
    "    '''\n",
    "    conn.execute(create_table_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Table renamed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route = 'KSFO_KLAX'\n",
    "data_file = 'KSFO_KLAX_2023-07-01_2023-07-31.csv'\n",
    "sqlite_file = 'KSFO_KLAX_2023-07-01_2023-07-31.sqlite'\n",
    "\n",
    "flights = pd.read_csv(f'../data/flight/{route}/{data_file}')\n",
    "if 'estdepartureairport' in flights.columns:\n",
    "    flights['departure_airport'] = flights['estdepartureairport']\n",
    "    flights['arrival_airport'] = flights['estarrivalairport']\n",
    "    flights.drop(['estdepartureairport', 'estarrivalairport'], axis='columns')\n",
    "\n",
    "flights['flight_id'] = [f'{row[\"icao24\"]}_{row[\"firstseen\"]}_{row[\"lastseen\"]}_{row[\"departure_airport\"]}_{row[\"arrival_airport\"]}' for _, row in flights.iterrows()]\n",
    "    \n",
    "\n",
    "flight_ids = [f[:-4] for f in os.listdir(f'../data/flight/{route}/state_vectors/') if len(f) == 42]\n",
    "valid_mask = flights['flight_id'].apply(lambda x: x in flight_ids)\n",
    "flights = flights[valid_mask]\n",
    "\n",
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect(f'../data/flight/{sqlite_file}')\n",
    "create_flights_table(conn)\n",
    "flights.to_sql('flights', conn, if_exists='replace', index=True)\n",
    "\n",
    "# Create state_vectors table\n",
    "create_state_vectors_table(conn)\n",
    "\n",
    "for i, flight_id in enumerate(flight_ids):\n",
    "    clear_output(wait=True)\n",
    "    print(f'flight_id: {flight_id} | {i}/{len(flight_ids)}')\n",
    "    file = f'../data/flight/{route}/state_vectors/{flight_id}.csv'\n",
    "    state_vectors = compressor.decode_to_dataframe_from_file(file)\n",
    "    state_vectors['flight_id'] = [flight_id]*len(state_vectors)\n",
    "    state_vectors['time_normalized'] = state_vectors['time'] - state_vectors.iloc[0]['time']\n",
    "    state_vectors.to_sql('state_vectors', conn, if_exists='append', index=False)\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_file = 'KSFO_KLAX_2023-07-01_2023-07-31.sqlite'\n",
    "\n",
    "conn = sqlite3.connect(f'../data/flight/{sqlite_file}')\n",
    "\n",
    "query = 'SELECT * FROM state_vectors LIMIT 1;'\n",
    "\n",
    "flights = pd.read_sql_query(query, conn)\n",
    "\n",
    "conn.close()\n",
    "flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_file = '2023-06-30_2022-08-01.sqlite'\n",
    "weather_dir = '../data/weather'\n",
    "stations_csv = 'stations_database.csv'\n",
    "\n",
    "os.system(f'rm {weather_dir}/../{sqlite_file}')\n",
    "stations = pd.read_csv(f'{weather_dir}/{stations_csv}', index_col=0)\n",
    "stations['station_id'] = stations['id']\n",
    "stations = stations.drop('id', axis='columns')\n",
    "stations\n",
    "\n",
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect(f'{weather_dir}/../{sqlite_file}')\n",
    "create_station_data_table(conn)\n",
    "stations.to_sql('weather_sations', conn, if_exists='replace', index=True)\n",
    "\n",
    "# Create state_vectors table\n",
    "create_weather_data_table(conn)\n",
    "\n",
    "files = [f for f in os.listdir(weather_dir) if len(f) == 25]\n",
    "for i, file in enumerate(files):\n",
    "    clear_output(wait=True)\n",
    "    print(f'file: {file} | {i}/{len(files)}')\n",
    "    weather_data = pd.read_csv(f'{weather_dir}/{file}', index_col=0)\n",
    "    weather_data['time'] = weather_data['timestamp']\n",
    "    weather_data['station_id'] = weather_data['station']\n",
    "    weather_data['METAR'] = weather_data['metar']\n",
    "\n",
    "    drops = ['timestamp', 'station', 'valid', 'lon', 'lat', 'metar',\n",
    "     'temperature_model', 'wind_model_E',\n",
    "           'wind_model_N', 'tmpf_sea_level', 'sknt_E_sea_level',\n",
    "           'sknt_N_sea_level', 'elevation', 'smps', 'smps_E', 'smps_N', 'tmpc', 'sigma',\n",
    "            'tmpf_model', 'sknt_E_model', 'sknt_N_model']\n",
    "    for drop in drops:\n",
    "        if drop in weather_data.columns:\n",
    "            weather_data.drop(drop, axis = 'columns' ,inplace=True)\n",
    "    weather_data.to_sql('weather_data', conn, if_exists='append', index=False)\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sqlite3\n",
    "# import pandas as pd\n",
    "\n",
    "# from src.common import utils\n",
    "\n",
    "# conn = sqlite3.connect('../data/weather/1673827200_1685923200.sqlite')\n",
    "\n",
    "# max_min_times_df = pd.read_sql_query(\"SELECT MAX(time) as max_time, MIN(time) as min_time FROM weather_data\", conn)\n",
    "# max_min_lats_df = pd.read_sql_query(\"SELECT MAX(lat) as max_lat, MIN(lat) as min_lat FROM weather_stations\", conn)\n",
    "# max_min_lons_df = pd.read_sql_query(\"SELECT MAX(lon) as max_lon, MIN(lon) as min_lon FROM weather_stations\", conn)\n",
    "\n",
    "# mid_t = np.mean(max_min_times_df.values)\n",
    "# mid_lat = np.mean(max_min_lats_df.values)\n",
    "# mid_lon = np.mean(max_min_lons_df.values)\n",
    "\n",
    "# t_1 = max_min_times_df['min_time'].values[0] - 1\n",
    "# t_2 = max_min_times_df['min_time'].values[0] + 3600 - 1\n",
    "\n",
    "# distance_thresh = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = f\"\"\"\n",
    "#     SELECT wd.*, ws.lat, ws.lon \n",
    "#     FROM weather_data wd\n",
    "#     JOIN weather_stations ws ON wd.station_id = ws.station_id\n",
    "#     WHERE wd.time BETWEEN {t_1} AND {t_2}\n",
    "# \"\"\"\n",
    "# weather_data_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# # conn.close()\n",
    "\n",
    "# weather_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FlightStats",
   "language": "python",
   "name": "flightstats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
